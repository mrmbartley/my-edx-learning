---
title: "Journey through Data Science: Machine Learning"
author: "Matt Bartley"
date: "4/30/2021"
output: html_document
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(message = FALSE)
knitr::opts_chunk$set(warning = FALSE)
devtools::install_github("rafalab/dslabs")
```

```{r libraries, include=FALSE}
library(devtools)
library(dslabs)
library(tidyverse)
library(caret)
library(readr)
library(Hmisc)
library(lubridate)
```


## Section 1: Introduction to Machine Learning

The introduction section highlights some beginner concepts in machine learning. Specifically:

- Outcomes are something that we want to predict and the features are the information we will use to make the prediction.

Goals for this section:
* Explain the difference between the outcome and the features
* Explain when to use classification and when to use prediction
* Explain the importance of prevalence
* Explain the difference between sensitivity and specificity



## Section 2: Machine Learning Basics

We want to predict sex using height. Note that sex in this example is a categorical variable with two possible outcomes: male, or female. We start by using the simplest possible model which is to randomly guess. Generally when training machine learning algorithms, we separate our data into a training set and a validation set. We can use the *createDataPartition*  function from the *caret* package. While we will perform this step initially, a random guess is not a machine learning algorithm and hence we will not require the training set to test performance on this approach.

```{r heights}
# load the data set
data(heights)


# define the outcome and predictors (or label and features)
y <- heights$sex
x <- heights$height

# generate training and test sets
set.seed(2, sample.kind = "Rounding")
test_index <- createDataPartition(y, times = 1, p = 0.5, list = FALSE)
test_set <- heights[test_index,]
train_set <- heights[-test_index,]


# guess the outcome and compute accuracy
y_hat <- sample(c("Male", "Female"), length(test_index), replace=TRUE) %>%
  factor(levels = levels(test_set$sex))
test_set %>% summarise(accuracy = mean(y_hat == sex))


# examine the distribution of heights by gender
heights %>% group_by(sex) %>% summarise(mean(height), sd(height))
heights %>% ggplot(aes(height, group=sex, colour=sex)) + geom_density()
heights %>% group_by(sex) %>% summarise(n = n()) %>% ungroup() %>% mutate(p = round(100*n/sum(n),1))


# obtain delta in height densities between males and females
heights.min <- min(heights$height)
heights.max <- max(heights$height)
density.male <- density(heights %>% filter(sex == "Male") %>% pull(height), from=heights.min, to=heights.max)
density.female <- density(heights %>% filter(sex == "Female") %>% pull(height), from=heights.min, to=heights.max)
density.diff <- density.male$y - density.female$y
density.intersect <- density.male$x[which(diff(density.diff > 0) != 0) + 1][1]


# use a height cutoff to guess the gender instead of random guess
y_hat <- ifelse(x > density.intersect, "Male", "Female") %>% factor(levels = levels(test_set$sex))
test_set %>% summarise(accuracy = mean(y_hat == sex))

# iterate over possible cutoff points
cutoff <- seq(61, 70)
accuracy <- map_dbl(cutoff, function(x){
  y_hat <- ifelse(train_set$height > x, "Male", "Female") %>% 
    factor(levels = levels(test_set$sex))
  mean(y_hat == train_set$sex)
})
data.frame(cutoff, accuracy) %>% 
  ggplot(aes(cutoff, accuracy)) + 
  geom_point() + 
  geom_line() 
max(accuracy)

best_cutoff <- cutoff[which.max(accuracy)]
best_cutoff

y_hat <- ifelse(test_set$height > best_cutoff, "Male", "Female") %>% 
  factor(levels = levels(test_set$sex))
y_hat <- factor(y_hat)
mean(y_hat == test_set$sex)
```

Notice that the success of our random guess approach is as expected, roughly **50%**. We improve upon this by using the cutoff which represents the intersection point of the densities, obtaining an accuracy of close to **60%**. We further improve about this by iterating over additional cutoff points on our training data to achieve an accuracy of **82%** on our test set with a cutoff height of 64.

Now we take a look at the confusion matrix and additional measures of accuracy. 

**Sensitivity** (or *Recall*) is a measure of an algorithm's ability to accurately predict a positive outcome. In other words, it is the percentage positive cases that are identified by the algorithm. This is calculated as:
$$Sensitivity=\frac{TP}{TP + FN}$$

**Specificity** is the measure of the algorithm's ability to accurately predict a negative outcome. Similar to above, it is the percentage of negative cases that are identified by the algorithm. This is calculated as:
$$Specificity=\frac{TN}{TN + FP}$$

```{r}
# tabulate each combination of prediction and actual value
table(predicted = y_hat, actual = test_set$sex)
test_set %>% 
  mutate(y_hat = y_hat) %>%
  group_by(sex) %>% 
  summarise(accuracy = mean(y_hat == sex))
prev <- mean(y == "Male")

confusionMatrix(data = y_hat, reference = test_set$sex)

```

Note that in situations where prevalence is low, precision becomes a more important metric. Precision is the given by the proportion of predicted positive cases that are actually positive. Formulaically:

$$Precision = \frac{TP}{TP+FP}$$

It is sometimes convenient to have a single numeric representation of the model's performance. For this we can consider either balanced accuracy or the F1 score. These are the arthimetic mean and harmonic mean respectively, of precision and recall. The harmonic mean is often used when averaging rates as in the example the average speed of a car. If a car travels at 60km/h for 20km and 40km/h for 10km, the correct average speed cannot be obtained by the arithmetic mean (50km/h) as it does not account for the amount of time traveling at the two distinct speeds. 

$$Balanced Accuracy = \frac{Precision + Recall}{2}$$
$$F1 Score = 2\times\frac{precision \times recall}{precision + recall}$$



```{r F1_Score}
# maximize F-score
cutoff <- seq(61, 70)
F_1 <- map_dbl(cutoff, function(x){
  y_hat <- ifelse(train_set$height > x, "Male", "Female") %>% 
    factor(levels = levels(test_set$sex))
  F_meas(data = y_hat, reference = factor(train_set$sex))
})

data.frame(cutoff, F_1) %>% 
  ggplot(aes(cutoff, F_1)) + 
  geom_point() + 
  geom_line()

max(F_1)

best_cutoff <- cutoff[which.max(F_1)]
best_cutoff

y_hat <- ifelse(test_set$height > best_cutoff, "Male", "Female") %>% 
  factor(levels = levels(test_set$sex))

confusionMatrix(data = y_hat, reference = test_set$sex)

```










```{r ROC}
p <- 0.9
n <- length(test_index)
y_hat <- sample(c("Male", "Female"), n, replace = TRUE, prob=c(p, 1-p)) %>% 
  factor(levels = levels(test_set$sex))
mean(y_hat == test_set$sex)

# ROC curve
probs <- seq(0, 1, length.out = 10)
guessing <- map_df(probs, function(p){
  y_hat <- 
    sample(c("Male", "Female"), n, replace = TRUE, prob=c(p, 1-p)) %>% 
    factor(levels = c("Female", "Male"))
  list(method = "Guessing",
       FPR = 1 - specificity(y_hat, test_set$sex),
       TPR = sensitivity(y_hat, test_set$sex))
})
guessing %>% qplot(FPR, TPR, data =., xlab = "1 - Specificity", ylab = "Sensitivity")

cutoffs <- c(50, seq(60, 75), 80)
height_cutoff <- map_df(cutoffs, function(x){
  y_hat <- ifelse(test_set$height > x, "Male", "Female") %>% 
    factor(levels = c("Female", "Male"))
   list(method = "Height cutoff",
        FPR = 1-specificity(y_hat, test_set$sex),
        TPR = sensitivity(y_hat, test_set$sex))
})

# plot both curves together
bind_rows(guessing, height_cutoff) %>%
  ggplot(aes(FPR, TPR, color = method)) +
  geom_line() +
  geom_point() +
  xlab("1 - Specificity") +
  ylab("Sensitivity")

library(ggrepel)
map_df(cutoffs, function(x){
  y_hat <- ifelse(test_set$height > x, "Male", "Female") %>% 
    factor(levels = c("Female", "Male"))
   list(method = "Height cutoff",
        cutoff = x, 
        FPR = 1-specificity(y_hat, test_set$sex),
        TPR = sensitivity(y_hat, test_set$sex))
}) %>%
  ggplot(aes(FPR, TPR, label = cutoff)) +
  geom_line() +
  geom_point() +
  geom_text_repel(nudge_x = 0.01, nudge_y = -0.01)

# plot precision against recall
guessing <- map_df(probs, function(p){
  y_hat <- sample(c("Male", "Female"), length(test_index), 
                  replace = TRUE, prob=c(p, 1-p)) %>% 
    factor(levels = c("Female", "Male"))
  list(method = "Guess",
    recall = sensitivity(y_hat, test_set$sex),
    precision = precision(y_hat, test_set$sex))
})

height_cutoff <- map_df(cutoffs, function(x){
  y_hat <- ifelse(test_set$height > x, "Male", "Female") %>% 
    factor(levels = c("Female", "Male"))
  list(method = "Height cutoff",
       recall = sensitivity(y_hat, test_set$sex),
    precision = precision(y_hat, test_set$sex))
})

bind_rows(guessing, height_cutoff) %>%
  ggplot(aes(recall, precision, color = method)) +
  geom_line() +
  geom_point()
guessing <- map_df(probs, function(p){
  y_hat <- sample(c("Male", "Female"), length(test_index), replace = TRUE, 
                  prob=c(p, 1-p)) %>% 
    factor(levels = c("Male", "Female"))
  list(method = "Guess",
    recall = sensitivity(y_hat, relevel(test_set$sex, "Male", "Female")),
    precision = precision(y_hat, relevel(test_set$sex, "Male", "Female")))
})

height_cutoff <- map_df(cutoffs, function(x){
  y_hat <- ifelse(test_set$height > x, "Male", "Female") %>% 
    factor(levels = c("Male", "Female"))
  list(method = "Height cutoff",
       recall = sensitivity(y_hat, relevel(test_set$sex, "Male", "Female")),
    precision = precision(y_hat, relevel(test_set$sex, "Male", "Female")))
})
bind_rows(guessing, height_cutoff) %>%
  ggplot(aes(recall, precision, color = method)) +
  geom_line() +
  geom_point()


```

### Seciton 2.1 Comprehension Check

```{r}

dat <- mutate(reported_heights, date_time = ymd_hms(time_stamp)) %>%
  filter(date_time >= make_date(2016, 01, 25) & date_time < make_date(2016, 02, 1)) %>%
  mutate(type = ifelse(day(date_time) == 25 & hour(date_time) == 8 & between(minute(date_time), 15, 30), "inclass","online")) %>%
  select(sex, type)

y <- factor(dat$sex, c("Female", "Male"))
x <- dat$type

data(iris)
iris <- iris[-which(iris$Species=='setosa'),]
y <- iris$Species

```


```{r 2.1.Q1}
dat %>% group_by(type, sex) %>% summarise(n = n()) %>% mutate(p = n/sum(n))
```

```{r 2.1.Q2}
prediction <- dat %>% 
  group_by(type, sex) %>% 
  summarise(n = n()) %>% 
  mutate(p = n/sum(n), max_p = max(n/sum(n))) %>% 
  filter(p == max_p) %>% 
  ungroup() %>% 
  select(type, sex)

dat <- dat %>% 
  left_join(prediction, by = c("type")) 

dat %>% 
  mutate(correct = sex.x == sex.y) %>%
  summarise(accuracy = mean(correct))
```


```{r 2.1.Q3}
table(dat$sex.x, dat$sex.y)
```

```{r 2.1.Q4}
sensitivity(as.factor(dat$sex.y), as.factor(dat$sex.x))

```


```{r 2.1.Q5}
specificity(as.factor(dat$sex.y), as.factor(dat$sex.x))

```

```{r 2.1.Q6}
dat %>% group_by(sex.x) %>% summarise(n = n()) %>% mutate(p = n/sum(n))
```


```{r 2.1.Q7}
# set.seed(2) # if using R 3.5 or earlier
set.seed(2, sample.kind="Rounding") # if using R 3.6 or later
test_index <- createDataPartition(y,times=1,p=0.5,list=FALSE)
test <- iris[test_index,]
train <- iris[-test_index,]
```



```{r 2.1.Q8}

# Sepal Length Predictor
cutoff <- seq(min(iris$Sepal.Length),max(iris$Sepal.Length),0.1)

accuracy <- map_dbl(cutoff, function(x){
  y_hat <- ifelse(train$Sepal.Length > x, "virginica", "versicolor") %>% 
    factor(levels = levels(train$Species))
  mean(y_hat == train$Species)
})
  
data.frame(cutoff, accuracy) %>% 
  ggplot(aes(cutoff, accuracy)) + 
  geom_point() + 
  geom_line()

max(accuracy)


# Sepal Width Predictor
cutoff <- seq(min(iris$Sepal.Width),max(iris$Sepal.Width),0.1)

accuracy <- map_dbl(cutoff, function(x){
  y_hat <- ifelse(train$Sepal.Width > x, "virginica", "versicolor") %>% 
    factor(levels = levels(train$Species))
  mean(y_hat == train$Species)
})
  
data.frame(cutoff, accuracy) %>% 
  ggplot(aes(cutoff, accuracy)) + 
  geom_point() + 
  geom_line()

max(accuracy)


# Petal Length Predictor

cutoff <- seq(min(iris$Petal.Length),max(iris$Petal.Length),0.1)

accuracy <- map_dbl(cutoff, function(x){
  y_hat <- ifelse(train$Petal.Length > x, "virginica", "versicolor") %>% 
    factor(levels = levels(train$Species))
  mean(y_hat == train$Species)
})
  
data.frame(cutoff, accuracy) %>% 
  ggplot(aes(cutoff, accuracy)) + 
  geom_point() + 
  geom_line()

max(accuracy)

# Petal Width Predictor

cutoff <- seq(min(iris$Petal.Width),max(iris$Petal.Width),0.1)

accuracy <- map_dbl(cutoff, function(x){
  y_hat <- ifelse(train$Petal.Width > x, "virginica", "versicolor") %>% 
    factor(levels = levels(train$Species))
  mean(y_hat == train$Species)
})
  
data.frame(cutoff, accuracy) %>% 
  ggplot(aes(cutoff, accuracy)) + 
  geom_point() + 
  geom_line()

max(accuracy)



```

```{r 2.1.Q9}

cutoff <- seq(min(iris$Petal.Length),max(iris$Petal.Length),0.1)

accuracy <- map_dbl(cutoff, function(x){
  y_hat <- ifelse(train$Petal.Length > x, "virginica", "versicolor") %>% 
    factor(levels = levels(train$Species))
  mean(y_hat == train$Species)
})
  
data.frame(cutoff, accuracy) %>% 
  ggplot(aes(cutoff, accuracy)) + 
  geom_point() + 
  geom_line()

max(accuracy)

smart_cutoff <- min(cutoff[accuracy == max(accuracy)])

y_hat <- ifelse(test$Petal.Length > smart_cutoff, "virginica", "versicolor") %>% factor(levels = levels(test$Species))
mean(y_hat == test$Species)

```


```{r 2.1.Q10}
# Sepal Length Predictor
cutoff <- seq(min(iris$Sepal.Length),max(iris$Sepal.Length),0.1)

accuracy <- map_dbl(cutoff, function(x){
  y_hat <- ifelse(test$Sepal.Length > x, "virginica", "versicolor") %>% 
    factor(levels = levels(test$Species))
  mean(y_hat == test$Species)
})
  
data.frame(cutoff, accuracy) %>% 
  ggplot(aes(cutoff, accuracy)) + 
  geom_point() + 
  geom_line()

max(accuracy)


# Sepal Width Predictor
cutoff <- seq(min(iris$Sepal.Width),max(iris$Sepal.Width),0.1)

accuracy <- map_dbl(cutoff, function(x){
  y_hat <- ifelse(test$Sepal.Width > x, "virginica", "versicolor") %>% 
    factor(levels = levels(test$Species))
  mean(y_hat == test$Species)
})
  
data.frame(cutoff, accuracy) %>% 
  ggplot(aes(cutoff, accuracy)) + 
  geom_point() + 
  geom_line()

max(accuracy)


# Petal Length Predictor

cutoff <- seq(min(iris$Petal.Length),max(iris$Petal.Length),0.1)

accuracy <- map_dbl(cutoff, function(x){
  y_hat <- ifelse(test$Petal.Length > x, "virginica", "versicolor") %>% 
    factor(levels = levels(test$Species))
  mean(y_hat == test$Species)
})
  
data.frame(cutoff, accuracy) %>% 
  ggplot(aes(cutoff, accuracy)) + 
  geom_point() + 
  geom_line()

max(accuracy)

# Petal Width Predictor

cutoff <- seq(min(iris$Petal.Width),max(iris$Petal.Width),0.1)

accuracy <- map_dbl(cutoff, function(x){
  y_hat <- ifelse(test$Petal.Width > x, "virginica", "versicolor") %>% 
    factor(levels = levels(test$Species))
  mean(y_hat == test$Species)
})
  
data.frame(cutoff, accuracy) %>% 
  ggplot(aes(cutoff, accuracy)) + 
  geom_point() + 
  geom_line()

max(accuracy)
```


```{r 2.1.Q11}
# what does this plot do?
plot(iris,pch=21,bg=iris$Species)

# Petal Length Predictor

cutoff <- seq(min(iris$Petal.Length),max(iris$Petal.Length),0.1)

accuracy <- map_dbl(cutoff, function(x){
  y_hat <- ifelse(train$Petal.Length > x, "virginica", "versicolor") %>% 
    factor(levels = levels(train$Species))
  mean(y_hat == train$Species)
})
  
data.frame(cutoff, accuracy) %>% 
  ggplot(aes(cutoff, accuracy)) + 
  geom_point() + 
  geom_line()

max(accuracy)
PL_cutoff <- min(cutoff[accuracy == max(accuracy)])

# Petal Width Predictor

cutoff <- seq(min(iris$Petal.Width),max(iris$Petal.Width),0.1)

accuracy <- map_dbl(cutoff, function(x){
  y_hat <- ifelse(train$Petal.Width > x, "virginica", "versicolor") %>% 
    factor(levels = levels(train$Species))
  mean(y_hat == train$Species)
})
  
data.frame(cutoff, accuracy) %>% 
  ggplot(aes(cutoff, accuracy)) + 
  geom_point() + 
  geom_line()

max(accuracy)
PW_cutoff <- min(cutoff[accuracy == max(accuracy)])


y_hat <- ifelse(test$Petal.Length > PL_cutoff | test$Petal.Width > PW_cutoff, "virginica", "versicolor") %>% factor(levels = levels(test$Species))
mean(y_hat == test$Species)

```




### Section 2.2 Comprehension Check

```{r 2.2.Q1}
Test_Sensitivity <- 0.85
Test_Specificity <- 0.90
Incidence_Rate <- 0.02

Pr_DiseaseCondTestPositive <- Test_Sensitivity * Incidence_Rate / (Test_Sensitivity * Incidence_Rate + (1 - Test_Specificity)*(1 - Incidence_Rate))
Pr_DiseaseCondTestPositive

```


```{r 2.2.Q2}
# set.seed(1) # if using R 3.5 or earlier
set.seed(1, sample.kind = "Rounding") # if using R 3.6 or later
disease <- sample(c(0,1), size=1e6, replace=TRUE, prob=c(0.98,0.02))
test <- rep(NA, 1e6)
test[disease==0] <- sample(c(0,1), size=sum(disease==0), replace=TRUE, prob=c(0.90,0.10))
test[disease==1] <- sample(c(0,1), size=sum(disease==1), replace=TRUE, prob=c(0.15, 0.85))

test %>% as_tibble() %>% ggplot(aes(value)) + geom_density()
mean(test)
```

```{r 2.2.Q3}
# prob disease | negative == prob negative | disease * prob disease / prob negative
(1 - mean(test[disease==1])) * mean(disease) / (1 - mean(test))
```

```{r 2.2.Q4}
# prob disease | positive == prob positive | disease * prob disease / prob positive
(mean(test[disease==1])) * mean(disease) / (mean(test))
```

```{r 2.2.Q5}
# lift = prob disease | positive / prob disease
(mean(test[disease==1]) * mean(disease) / mean(test)) / mean(disease)

```

```{r 2.2.Q6}
heights %>%
  mutate(height = round(height)) %>%
  group_by(height) %>%
  summarise(p = mean(sex == "Male")) %>%
  qplot(height, p, data =.)

```


```{r 2.2.Q7}
ps <- seq(0, 1, 0.1)

heights %>%
  mutate(g = cut(height, quantile(height, ps), include.lowest = TRUE)) %>%
  group_by(g) %>%
  summarise(p = mean(sex == "Male"), height = mean(height)) %>%
  qplot(height, p, data =.)

```


```{r 2.2.Q8}
Sigma <- 9*matrix(c(1,0.5,0.5,1), 2, 2)
dat <- MASS::mvrnorm(n = 10000, c(69, 69), Sigma) %>%
	data.frame() %>% setNames(c("x", "y"))

plot(dat)


ps <- seq(0, 1, 0.1)
dat %>% 
	mutate(g = cut(x, quantile(x, ps), include.lowest = TRUE)) %>%
  group_by(g) %>%
  summarise(x = mean(x), y = mean(y)) %>%
	qplot(x, y, data =.)
```


## Section 3: Linear Regression for Prediction, Smoothing, and Working with Matrices Overview

THe focus of this section is on using linear regression for prediction. It however has limitations in more complex analysis but can be a useful tool for smoothing noisy data.

We can start with the Galton heights example and compare the performance of naive prediction to regression analysis. Note that we are implicitly assuming that the data follows a bivariate normal distribution which should be validated in practice. We can do this by generating quantile plots for one variable which has been stratified by the other.

```{r}
library(HistData)
galton_heights <- GaltonFamilies %>%
  filter(childNum == 1 & gender == "male") %>%
  select(father, childHeight) %>%
  rename(son = childHeight)

head(galton_heights)

# separate data into training and test sets
test_index <- galton_heights$son %>% createDataPartition(times = 1, p = 0.5, list=FALSE)
train_set <- galton_heights %>% slice(-test_index)
test_set <- galton_heights %>% slice(test_index)

# perform naive prediction using average height of son and report accuracy using MSE
naive_pred <- mean(train_set$son)
mean((naive_pred - test_set$son)^2)

# perform regression fit to predict son height using father height and report accuracy using MSE
fit <- lm(son ~ father, data = train_set)
fit$coef
y_hat <- fit$coef[1] + fit$coef[2]*test_set$father
mean((y_hat - test_set$son)^2)

# validating the bivariate normal assumption: stratify by son heights by the standardized father heights
galton_heights %>%
  mutate(z_father = round((father - mean(father)) / sd(father))) %>% # standardize father heights
  filter(z_father %in% -2:2) %>% # remove outliers
  ggplot() + 
  stat_qq(aes(sample = son)) + 
  facet_wrap(~ z_father)

# use the predict function to generate our new predictions instead of the coefficients
y_hat <- predict(fit, test_set)
mean((y_hat - test_set$son)^2)

?predict.lm

```


### Section 3.1: comprehension check


```{r 3.1.Q1}

# set.seed(1) # if using R 3.5 or earlier
set.seed(1, sample.kind="Rounding") # if using R 3.6 or later
n <- 100
Sigma <- 9*matrix(c(1.0, 0.5, 0.5, 1.0), 2, 2)
dat <- MASS::mvrnorm(n = 100, c(69, 69), Sigma) %>%
      data.frame() %>% setNames(c("x", "y"))



my_func <- function() {
  index_dat <- dat$y %>% createDataPartition(times = 1, p = 0.5, list=FALSE)
  train_dat <- dat %>% slice(-index_dat)
  test_dat <- dat %>% slice(index_dat)
  fit_dat <- lm(y ~ x, data = train_dat)
  y_hat_dat <- predict.lm(fit_dat, test_dat)
  #y_hat_dat <- fit_dat$coef[1] + fit_dat$coef[2]*test_dat$x
  sqrt(mean((y_hat_dat - test_dat$y)^2))
}

set.seed(1, sample.kind="Rounding")
RMSE <- replicate(n, my_func())

mean(RMSE)
sd(RMSE)

```

```{r 3.1.Q2}

n <- c(100, 500, 1000, 5000, 10000)
set.seed(1, sample.kind="Rounding")
sapply(n, function(n) {
  Sigma <- 9*matrix(c(1.0, 0.5, 0.5, 1.0), 2, 2)
  dat <- MASS::mvrnorm(n = n, c(69, 69), Sigma) %>% data.frame() %>% setNames(c("x", "y"))
  RMSE <- replicate(100, {
    index_dat <- dat$y %>% createDataPartition(times = 1, p = 0.5, list=FALSE)
    train_dat <- dat %>% slice(-index_dat)
    test_dat <- dat %>% slice(index_dat)
    fit_dat <- lm(y ~ x, data = train_dat)
    y_hat_dat <- predict.lm(fit_dat, test_dat)
    sqrt(mean((y_hat_dat - test_dat$y)^2))
    })
  c(mean(RMSE), sd(RMSE))
})



```

```{r 3.1.Q4}
# set.seed(1) # if using R 3.5 or earlier
set.seed(1, sample.kind="Rounding") # if using R 3.6 or later
n <- 100
Sigma <- 9*matrix(c(1.0, 0.95, 0.95, 1.0), 2, 2)
dat <- MASS::mvrnorm(n = 100, c(69, 69), Sigma) %>%
	data.frame() %>% setNames(c("x", "y"))

my_func <- function() {
  index_dat <- dat$y %>% createDataPartition(times = 1, p = 0.5, list=FALSE)
  train_dat <- dat %>% slice(-index_dat)
  test_dat <- dat %>% slice(index_dat)
  fit_dat <- lm(y ~ x, data = train_dat)
  y_hat_dat <- predict.lm(fit_dat, test_dat)
  sqrt(mean((y_hat_dat - test_dat$y)^2))
}

set.seed(1, sample.kind="Rounding")
RMSE <- replicate(n, my_func())

mean(RMSE)
sd(RMSE)
```

```{r 3.1.Q6}
# set.seed(1) # if using R 3.5 or earlier
set.seed(1, sample.kind="Rounding") # if using R 3.6 or later
Sigma <- matrix(c(1.0, 0.75, 0.75, 0.75, 1.0, 0.25, 0.75, 0.25, 1.0), 3, 3)
dat <- MASS::mvrnorm(n = 100, c(0, 0, 0), Sigma) %>%
	data.frame() %>% setNames(c("y", "x_1", "x_2"))

cor(dat)

set.seed(1, sample.kind="Rounding")
index_dat <- dat$y %>% createDataPartition(times = 1, p = 0.5, list=FALSE)
train_dat <- dat %>% slice(-index_dat)
test_dat <- dat %>% slice(index_dat)

# train model on x_1
fit_dat <- lm(y ~ x_1, data = train_dat)
y_hat_dat <- predict.lm(fit_dat, test_dat)
sqrt(mean((y_hat_dat - test_dat$y)^2))

# train model on x_2
fit_dat <- lm(y ~ x_2, data = train_dat)
y_hat_dat <- predict.lm(fit_dat, test_dat)
sqrt(mean((y_hat_dat - test_dat$y)^2))

# train model on x_1 and x_2
fit_dat <- lm(y ~ x_1 + x_2, data = train_dat)
y_hat_dat <- predict.lm(fit_dat, test_dat)
sqrt(mean((y_hat_dat - test_dat$y)^2))



```


```{r 3.1.Q8}
# set.seed(1) # if using R 3.5 or earlier
set.seed(1, sample.kind="Rounding") # if using R 3.6 or later
Sigma <- matrix(c(1.0, 0.75, 0.75, 0.75, 1.0, 0.95, 0.75, 0.95, 1.0), 3, 3)
dat <- MASS::mvrnorm(n = 100, c(0, 0, 0), Sigma) %>%
	data.frame() %>% setNames(c("y", "x_1", "x_2"))

cor(dat)

set.seed(1, sample.kind="Rounding")
index_dat <- dat$y %>% createDataPartition(times = 1, p = 0.5, list=FALSE)
train_dat <- dat %>% slice(-index_dat)
test_dat <- dat %>% slice(index_dat)

# train model on x_1
fit_dat <- lm(y ~ x_1, data = train_dat)
y_hat_dat <- predict.lm(fit_dat, test_dat)
sqrt(mean((y_hat_dat - test_dat$y)^2))

# train model on x_2
fit_dat <- lm(y ~ x_2, data = train_dat)
y_hat_dat <- predict.lm(fit_dat, test_dat)
sqrt(mean((y_hat_dat - test_dat$y)^2))

# train model on x_1 and x_2
fit_dat <- lm(y ~ x_1 + x_2, data = train_dat)
y_hat_dat <- predict.lm(fit_dat, test_dat)
sqrt(mean((y_hat_dat - test_dat$y)^2))
```


