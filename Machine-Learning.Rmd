---
title: "Journey through Data Science: Machine Learning"
author: "Matt Bartley"
date: "4/30/2021"
output: html_document
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE) 
devtools::install_github("rafalab/dslabs")
```

```{r libraries, include=FALSE}
library(devtools)
library(dslabs)
library(tidyverse)
library(caret)
library(readr)
library(Hmisc)
library(lubridate)
```


## Section 1: Introduction to Machine Learning

The introduction section highlights some beginner concepts in machine learning. Specifically:

- Outcomes are something that we want to predict and the features are the information we will use to make the prediction.

Goals for this section:
* Explain the difference between the outcome and the features
* Explain when to use classification and when to use prediction
* Explain the importance of prevalence
* Explain the difference between sensitivity and specificity



## Section 2: Machine Learning Basics

We want to predict sex using height. Note that sex in this example is a categorical variable with two possible outcomes: male, or female. We start by using the simplest possible model which is to randomly guess. Generally when training machine learning algorithms, we separate our data into a training set and a validation set. We can use the *createDataPartition*  function from the *caret* package. While we will perform this step initially, a random guess is not a machine learning algorithm and hence we will not require the training set to test performance on this approach.

```{r heights}
# load the data set
data(heights)


# define the outcome and predictors (or label and features)
y <- heights$sex
x <- heights$height

# generate training and test sets
set.seed(2, sample.kind = "Rounding")
test_index <- createDataPartition(y, times = 1, p = 0.5, list = FALSE)
test_set <- heights[test_index,]
train_set <- heights[-test_index,]


# guess the outcome and compute accuracy
y_hat <- sample(c("Male", "Female"), length(test_index), replace=TRUE) %>%
  factor(levels = levels(test_set$sex))
test_set %>% summarise(accuracy = mean(y_hat == sex))


# examine the distribution of heights by gender
heights %>% group_by(sex) %>% summarise(mean(height), sd(height))
heights %>% ggplot(aes(height, group=sex, colour=sex)) + geom_density()
heights %>% group_by(sex) %>% summarise(n = n()) %>% ungroup() %>% mutate(p = round(100*n/sum(n),1))


# obtain delta in height densities between males and females
heights.min <- min(heights$height)
heights.max <- max(heights$height)
density.male <- density(heights %>% filter(sex == "Male") %>% pull(height), from=heights.min, to=heights.max)
density.female <- density(heights %>% filter(sex == "Female") %>% pull(height), from=heights.min, to=heights.max)
density.diff <- density.male$y - density.female$y
density.intersect <- density.male$x[which(diff(density.diff > 0) != 0) + 1][1]


# use a height cutoff to guess the gender instead of random guess
y_hat <- ifelse(x > density.intersect, "Male", "Female") %>% factor(levels = levels(test_set$sex))
test_set %>% summarise(accuracy = mean(y_hat == sex))

# iterate over possible cutoff points
cutoff <- seq(61, 70)
accuracy <- map_dbl(cutoff, function(x){
  y_hat <- ifelse(train_set$height > x, "Male", "Female") %>% 
    factor(levels = levels(test_set$sex))
  mean(y_hat == train_set$sex)
})
data.frame(cutoff, accuracy) %>% 
  ggplot(aes(cutoff, accuracy)) + 
  geom_point() + 
  geom_line() 
max(accuracy)

best_cutoff <- cutoff[which.max(accuracy)]
best_cutoff

y_hat <- ifelse(test_set$height > best_cutoff, "Male", "Female") %>% 
  factor(levels = levels(test_set$sex))
y_hat <- factor(y_hat)
mean(y_hat == test_set$sex)
```

Notice that the success of our random guess approach is as expected, roughly **50%**. We improve upon this by using the cutoff which represents the intersection point of the densities, obtaining an accuracy of close to **60%**. We further improve about this by iterating over additional cutoff points on our training data to achieve an accuracy of **82%** on our test set with a cutoff height of 64.

Now we take a look at the confusion matrix and additional measures of accuracy. 

**Sensitivity** (or *Recall*) is a measure of an algorithm's ability to accurately predict a positive outcome. In other words, it is the percentage positive cases that are identified by the algorithm. This is calculated as:
$$Sensitivity=\frac{TP}{TP + FN}$$

**Specificity** is the measure of the algorithm's ability to accurately predict a negative outcome. Similar to above, it is the percentage of negative cases that are identified by the algorithm. This is calculated as:
$$Specificity=\frac{TN}{TN + FP}$$

```{r}
# tabulate each combination of prediction and actual value
table(predicted = y_hat, actual = test_set$sex)
test_set %>% 
  mutate(y_hat = y_hat) %>%
  group_by(sex) %>% 
  summarise(accuracy = mean(y_hat == sex))
prev <- mean(y == "Male")

confusionMatrix(data = y_hat, reference = test_set$sex)

```

Note that in situations where prevalence is low, precision becomes a more important metric. Precision is the given by the proportion of predicted positive cases that are actually positive. Formulaically:

$$Precision = \frac{TP}{TP+FP}$$

It is sometimes convenient to have a single numeric representation of the model's performance. For this we can consider either balanced accuracy or the F1 score. These are the arthimetic mean and harmonic mean respectively, of precision and recall. The harmonic mean is often used when averaging rates as in the example the average speed of a car. If a car travels at 60km/h for 20km and 40km/h for 10km, the correct average speed cannot be obtained by the arithmetic mean (50km/h) as it does not account for the amount of time traveling at the two distinct speeds. 

$$Balanced Accuracy = \frac{Precision + Recall}{2}$$
$$F1 Score = 2\times\frac{precision \times recall}{precision + recall}$$



```{r F1_Score}
# maximize F-score
cutoff <- seq(61, 70)
F_1 <- map_dbl(cutoff, function(x){
  y_hat <- ifelse(train_set$height > x, "Male", "Female") %>% 
    factor(levels = levels(test_set$sex))
  F_meas(data = y_hat, reference = factor(train_set$sex))
})

data.frame(cutoff, F_1) %>% 
  ggplot(aes(cutoff, F_1)) + 
  geom_point() + 
  geom_line()

max(F_1)

best_cutoff <- cutoff[which.max(F_1)]
best_cutoff

y_hat <- ifelse(test_set$height > best_cutoff, "Male", "Female") %>% 
  factor(levels = levels(test_set$sex))

confusionMatrix(data = y_hat, reference = test_set$sex)

```










```{r ROC}
p <- 0.9
n <- length(test_index)
y_hat <- sample(c("Male", "Female"), n, replace = TRUE, prob=c(p, 1-p)) %>% 
  factor(levels = levels(test_set$sex))
mean(y_hat == test_set$sex)

# ROC curve
probs <- seq(0, 1, length.out = 10)
guessing <- map_df(probs, function(p){
  y_hat <- 
    sample(c("Male", "Female"), n, replace = TRUE, prob=c(p, 1-p)) %>% 
    factor(levels = c("Female", "Male"))
  list(method = "Guessing",
       FPR = 1 - specificity(y_hat, test_set$sex),
       TPR = sensitivity(y_hat, test_set$sex))
})
guessing %>% qplot(FPR, TPR, data =., xlab = "1 - Specificity", ylab = "Sensitivity")

cutoffs <- c(50, seq(60, 75), 80)
height_cutoff <- map_df(cutoffs, function(x){
  y_hat <- ifelse(test_set$height > x, "Male", "Female") %>% 
    factor(levels = c("Female", "Male"))
   list(method = "Height cutoff",
        FPR = 1-specificity(y_hat, test_set$sex),
        TPR = sensitivity(y_hat, test_set$sex))
})

# plot both curves together
bind_rows(guessing, height_cutoff) %>%
  ggplot(aes(FPR, TPR, color = method)) +
  geom_line() +
  geom_point() +
  xlab("1 - Specificity") +
  ylab("Sensitivity")

library(ggrepel)
map_df(cutoffs, function(x){
  y_hat <- ifelse(test_set$height > x, "Male", "Female") %>% 
    factor(levels = c("Female", "Male"))
   list(method = "Height cutoff",
        cutoff = x, 
        FPR = 1-specificity(y_hat, test_set$sex),
        TPR = sensitivity(y_hat, test_set$sex))
}) %>%
  ggplot(aes(FPR, TPR, label = cutoff)) +
  geom_line() +
  geom_point() +
  geom_text_repel(nudge_x = 0.01, nudge_y = -0.01)

# plot precision against recall
guessing <- map_df(probs, function(p){
  y_hat <- sample(c("Male", "Female"), length(test_index), 
                  replace = TRUE, prob=c(p, 1-p)) %>% 
    factor(levels = c("Female", "Male"))
  list(method = "Guess",
    recall = sensitivity(y_hat, test_set$sex),
    precision = precision(y_hat, test_set$sex))
})

height_cutoff <- map_df(cutoffs, function(x){
  y_hat <- ifelse(test_set$height > x, "Male", "Female") %>% 
    factor(levels = c("Female", "Male"))
  list(method = "Height cutoff",
       recall = sensitivity(y_hat, test_set$sex),
    precision = precision(y_hat, test_set$sex))
})

bind_rows(guessing, height_cutoff) %>%
  ggplot(aes(recall, precision, color = method)) +
  geom_line() +
  geom_point()
guessing <- map_df(probs, function(p){
  y_hat <- sample(c("Male", "Female"), length(test_index), replace = TRUE, 
                  prob=c(p, 1-p)) %>% 
    factor(levels = c("Male", "Female"))
  list(method = "Guess",
    recall = sensitivity(y_hat, relevel(test_set$sex, "Male", "Female")),
    precision = precision(y_hat, relevel(test_set$sex, "Male", "Female")))
})

height_cutoff <- map_df(cutoffs, function(x){
  y_hat <- ifelse(test_set$height > x, "Male", "Female") %>% 
    factor(levels = c("Male", "Female"))
  list(method = "Height cutoff",
       recall = sensitivity(y_hat, relevel(test_set$sex, "Male", "Female")),
    precision = precision(y_hat, relevel(test_set$sex, "Male", "Female")))
})
bind_rows(guessing, height_cutoff) %>%
  ggplot(aes(recall, precision, color = method)) +
  geom_line() +
  geom_point()


```

### Seciton 2.1 Comprehension Check

```{r}

dat <- mutate(reported_heights, date_time = ymd_hms(time_stamp)) %>%
  filter(date_time >= make_date(2016, 01, 25) & date_time < make_date(2016, 02, 1)) %>%
  mutate(type = ifelse(day(date_time) == 25 & hour(date_time) == 8 & between(minute(date_time), 15, 30), "inclass","online")) %>%
  select(sex, type)

y <- factor(dat$sex, c("Female", "Male"))
x <- dat$type

data(iris)
iris <- iris[-which(iris$Species=='setosa'),]
y <- iris$Species

```


```{r 2.1.Q1}
dat %>% group_by(type, sex) %>% summarise(n = n()) %>% mutate(p = n/sum(n))
```

```{r 2.1.Q2}
prediction <- dat %>% 
  group_by(type, sex) %>% 
  summarise(n = n()) %>% 
  mutate(p = n/sum(n), max_p = max(n/sum(n))) %>% 
  filter(p == max_p) %>% 
  ungroup() %>% 
  select(type, sex)

dat <- dat %>% 
  left_join(prediction, by = c("type")) 

dat %>% 
  mutate(correct = sex.x == sex.y) %>%
  summarise(accuracy = mean(correct))
```


```{r 2.1.Q3}
table(dat$sex.x, dat$sex.y)
```

```{r 2.1.Q4}
sensitivity(as.factor(dat$sex.y), as.factor(dat$sex.x))

```


```{r 2.1.Q5}
specificity(as.factor(dat$sex.y), as.factor(dat$sex.x))

```

```{r 2.1.Q6}
dat %>% group_by(sex.x) %>% summarise(n = n()) %>% mutate(p = n/sum(n))
```


```{r 2.1.Q7}
# set.seed(2) # if using R 3.5 or earlier
set.seed(2, sample.kind="Rounding") # if using R 3.6 or later
test_index <- createDataPartition(y,times=1,p=0.5,list=FALSE)
test <- iris[test_index,]
train <- iris[-test_index,]
```



```{r 2.1.Q8}

# Sepal Length Predictor
cutoff <- seq(min(iris$Sepal.Length),max(iris$Sepal.Length),0.1)

accuracy <- map_dbl(cutoff, function(x){
  y_hat <- ifelse(train$Sepal.Length > x, "virginica", "versicolor") %>% 
    factor(levels = levels(train$Species))
  mean(y_hat == train$Species)
})
  
data.frame(cutoff, accuracy) %>% 
  ggplot(aes(cutoff, accuracy)) + 
  geom_point() + 
  geom_line()

max(accuracy)


# Sepal Width Predictor
cutoff <- seq(min(iris$Sepal.Width),max(iris$Sepal.Width),0.1)

accuracy <- map_dbl(cutoff, function(x){
  y_hat <- ifelse(train$Sepal.Width > x, "virginica", "versicolor") %>% 
    factor(levels = levels(train$Species))
  mean(y_hat == train$Species)
})
  
data.frame(cutoff, accuracy) %>% 
  ggplot(aes(cutoff, accuracy)) + 
  geom_point() + 
  geom_line()

max(accuracy)


# Petal Length Predictor

cutoff <- seq(min(iris$Petal.Length),max(iris$Petal.Length),0.1)

accuracy <- map_dbl(cutoff, function(x){
  y_hat <- ifelse(train$Petal.Length > x, "virginica", "versicolor") %>% 
    factor(levels = levels(train$Species))
  mean(y_hat == train$Species)
})
  
data.frame(cutoff, accuracy) %>% 
  ggplot(aes(cutoff, accuracy)) + 
  geom_point() + 
  geom_line()

max(accuracy)

# Petal Width Predictor

cutoff <- seq(min(iris$Petal.Width),max(iris$Petal.Width),0.1)

accuracy <- map_dbl(cutoff, function(x){
  y_hat <- ifelse(train$Petal.Width > x, "virginica", "versicolor") %>% 
    factor(levels = levels(train$Species))
  mean(y_hat == train$Species)
})
  
data.frame(cutoff, accuracy) %>% 
  ggplot(aes(cutoff, accuracy)) + 
  geom_point() + 
  geom_line()

max(accuracy)



```

```{r 2.1.Q9}

cutoff <- seq(min(iris$Petal.Length),max(iris$Petal.Length),0.1)

accuracy <- map_dbl(cutoff, function(x){
  y_hat <- ifelse(train$Petal.Length > x, "virginica", "versicolor") %>% 
    factor(levels = levels(train$Species))
  mean(y_hat == train$Species)
})
  
data.frame(cutoff, accuracy) %>% 
  ggplot(aes(cutoff, accuracy)) + 
  geom_point() + 
  geom_line()

max(accuracy)

smart_cutoff <- min(cutoff[accuracy == max(accuracy)])

y_hat <- ifelse(test$Petal.Length > smart_cutoff, "virginica", "versicolor") %>% factor(levels = levels(test$Species))
mean(y_hat == test$Species)

```


```{r 2.1.Q10}
# Sepal Length Predictor
cutoff <- seq(min(iris$Sepal.Length),max(iris$Sepal.Length),0.1)

accuracy <- map_dbl(cutoff, function(x){
  y_hat <- ifelse(test$Sepal.Length > x, "virginica", "versicolor") %>% 
    factor(levels = levels(test$Species))
  mean(y_hat == test$Species)
})
  
data.frame(cutoff, accuracy) %>% 
  ggplot(aes(cutoff, accuracy)) + 
  geom_point() + 
  geom_line()

max(accuracy)


# Sepal Width Predictor
cutoff <- seq(min(iris$Sepal.Width),max(iris$Sepal.Width),0.1)

accuracy <- map_dbl(cutoff, function(x){
  y_hat <- ifelse(test$Sepal.Width > x, "virginica", "versicolor") %>% 
    factor(levels = levels(test$Species))
  mean(y_hat == test$Species)
})
  
data.frame(cutoff, accuracy) %>% 
  ggplot(aes(cutoff, accuracy)) + 
  geom_point() + 
  geom_line()

max(accuracy)


# Petal Length Predictor

cutoff <- seq(min(iris$Petal.Length),max(iris$Petal.Length),0.1)

accuracy <- map_dbl(cutoff, function(x){
  y_hat <- ifelse(test$Petal.Length > x, "virginica", "versicolor") %>% 
    factor(levels = levels(test$Species))
  mean(y_hat == test$Species)
})
  
data.frame(cutoff, accuracy) %>% 
  ggplot(aes(cutoff, accuracy)) + 
  geom_point() + 
  geom_line()

max(accuracy)

# Petal Width Predictor

cutoff <- seq(min(iris$Petal.Width),max(iris$Petal.Width),0.1)

accuracy <- map_dbl(cutoff, function(x){
  y_hat <- ifelse(test$Petal.Width > x, "virginica", "versicolor") %>% 
    factor(levels = levels(test$Species))
  mean(y_hat == test$Species)
})
  
data.frame(cutoff, accuracy) %>% 
  ggplot(aes(cutoff, accuracy)) + 
  geom_point() + 
  geom_line()

max(accuracy)
```


```{r 2.1.Q11}
# what does this plot do?
plot(iris,pch=21,bg=iris$Species)

# Petal Length Predictor

cutoff <- seq(min(iris$Petal.Length),max(iris$Petal.Length),0.1)

accuracy <- map_dbl(cutoff, function(x){
  y_hat <- ifelse(train$Petal.Length > x, "virginica", "versicolor") %>% 
    factor(levels = levels(train$Species))
  mean(y_hat == train$Species)
})
  
data.frame(cutoff, accuracy) %>% 
  ggplot(aes(cutoff, accuracy)) + 
  geom_point() + 
  geom_line()

max(accuracy)
PL_cutoff <- min(cutoff[accuracy == max(accuracy)])

# Petal Width Predictor

cutoff <- seq(min(iris$Petal.Width),max(iris$Petal.Width),0.1)

accuracy <- map_dbl(cutoff, function(x){
  y_hat <- ifelse(train$Petal.Width > x, "virginica", "versicolor") %>% 
    factor(levels = levels(train$Species))
  mean(y_hat == train$Species)
})
  
data.frame(cutoff, accuracy) %>% 
  ggplot(aes(cutoff, accuracy)) + 
  geom_point() + 
  geom_line()

max(accuracy)
PW_cutoff <- min(cutoff[accuracy == max(accuracy)])


y_hat <- ifelse(test$Petal.Length > PL_cutoff | test$Petal.Width > PW_cutoff, "virginica", "versicolor") %>% factor(levels = levels(test$Species))
mean(y_hat == test$Species)

```




### Section 2.2 Comprehension Check

```{r 2.2.Q1}
Test_Sensitivity <- 0.85
Test_Specificity <- 0.90
Incidence_Rate <- 0.02

Pr_DiseaseCondTestPositive <- Test_Sensitivity * Incidence_Rate / (Test_Sensitivity * Incidence_Rate + (1 - Test_Specificity)*(1 - Incidence_Rate))
Pr_DiseaseCondTestPositive

```


```{r 2.2.Q2}
# set.seed(1) # if using R 3.5 or earlier
set.seed(1, sample.kind = "Rounding") # if using R 3.6 or later
disease <- sample(c(0,1), size=1e6, replace=TRUE, prob=c(0.98,0.02))
test <- rep(NA, 1e6)
test[disease==0] <- sample(c(0,1), size=sum(disease==0), replace=TRUE, prob=c(0.90,0.10))
test[disease==1] <- sample(c(0,1), size=sum(disease==1), replace=TRUE, prob=c(0.15, 0.85))

test %>% as_tibble() %>% ggplot(aes(value)) + geom_density()
mean(test)
```

```{r 2.2.Q3}
# prob disease | negative == prob negative | disease * prob disease / prob negative
(1 - mean(test[disease==1])) * mean(disease) / (1 - mean(test))
```

```{r 2.2.Q4}
# prob disease | positive == prob positive | disease * prob disease / prob positive
(mean(test[disease==1])) * mean(disease) / (mean(test))
```

```{r 2.2.Q5}
# lift = prob disease | positive / prob disease
(mean(test[disease==1]) * mean(disease) / mean(test)) / mean(disease)

```

```{r 2.2.Q6}
heights %>%
  mutate(height = round(height)) %>%
  group_by(height) %>%
  summarise(p = mean(sex == "Male")) %>%
  qplot(height, p, data =.)

```


```{r 2.2.Q7}
ps <- seq(0, 1, 0.1)

heights %>%
  mutate(g = cut(height, quantile(height, ps), include.lowest = TRUE)) %>%
  group_by(g) %>%
  summarise(p = mean(sex == "Male"), height = mean(height)) %>%
  qplot(height, p, data =.)

```


```{r 2.2.Q8}
Sigma <- 9*matrix(c(1,0.5,0.5,1), 2, 2)
dat <- MASS::mvrnorm(n = 10000, c(69, 69), Sigma) %>%
	data.frame() %>% setNames(c("x", "y"))

plot(dat)


ps <- seq(0, 1, 0.1)
dat %>% 
	mutate(g = cut(x, quantile(x, ps), include.lowest = TRUE)) %>%
  group_by(g) %>%
  summarise(x = mean(x), y = mean(y)) %>%
	qplot(x, y, data =.)
```


## Section 3: Linear Regression for Prediction, Smoothing, and Working with Matrices Overview

THe focus of this section is on using linear regression for prediction. It however has limitations in more complex analysis but can be a useful tool for smoothing noisy data.

We can start with the Galton heights example and compare the performance of naive prediction to regression analysis. Note that we are implicitly assuming that the data follows a bivariate normal distribution which should be validated in practice. We can do this by generating quantile plots for one variable which has been stratified by the other.

```{r}
library(HistData)
galton_heights <- GaltonFamilies %>%
  filter(childNum == 1 & gender == "male") %>%
  select(father, childHeight) %>%
  rename(son = childHeight)

head(galton_heights)

# separate data into training and test sets
test_index <- galton_heights$son %>% createDataPartition(times = 1, p = 0.5, list=FALSE)
train_set <- galton_heights %>% slice(-test_index)
test_set <- galton_heights %>% slice(test_index)

# perform naive prediction using average height of son and report accuracy using MSE
naive_pred <- mean(train_set$son)
mean((naive_pred - test_set$son)^2)

# perform regression fit to predict son height using father height and report accuracy using MSE
fit <- lm(son ~ father, data = train_set)
fit$coef
y_hat <- fit$coef[1] + fit$coef[2]*test_set$father
mean((y_hat - test_set$son)^2)

# validating the bivariate normal assumption: stratify by son heights by the standardized father heights
galton_heights %>%
  mutate(z_father = round((father - mean(father)) / sd(father))) %>% # standardize father heights
  filter(z_father %in% -2:2) %>% # remove outliers
  ggplot() + 
  stat_qq(aes(sample = son)) + 
  facet_wrap(~ z_father)

# use the predict function to generate our new predictions instead of the coefficients
y_hat <- predict(fit, test_set)
mean((y_hat - test_set$son)^2)

?predict.lm

```


### Section 3.1: comprehension check


```{r 3.1.Q1}

# set.seed(1) # if using R 3.5 or earlier
set.seed(1, sample.kind="Rounding") # if using R 3.6 or later
n <- 100
Sigma <- 9*matrix(c(1.0, 0.5, 0.5, 1.0), 2, 2)
dat <- MASS::mvrnorm(n = 100, c(69, 69), Sigma) %>%
      data.frame() %>% setNames(c("x", "y"))



my_func <- function() {
  index_dat <- dat$y %>% createDataPartition(times = 1, p = 0.5, list=FALSE)
  train_dat <- dat %>% slice(-index_dat)
  test_dat <- dat %>% slice(index_dat)
  fit_dat <- lm(y ~ x, data = train_dat)
  y_hat_dat <- predict.lm(fit_dat, test_dat)
  #y_hat_dat <- fit_dat$coef[1] + fit_dat$coef[2]*test_dat$x
  sqrt(mean((y_hat_dat - test_dat$y)^2))
}

set.seed(1, sample.kind="Rounding")
RMSE <- replicate(n, my_func())

mean(RMSE)
sd(RMSE)

```

```{r 3.1.Q2}

n <- c(100, 500, 1000, 5000, 10000)
set.seed(1, sample.kind="Rounding")
sapply(n, function(n) {
  Sigma <- 9*matrix(c(1.0, 0.5, 0.5, 1.0), 2, 2)
  dat <- MASS::mvrnorm(n = n, c(69, 69), Sigma) %>% data.frame() %>% setNames(c("x", "y"))
  RMSE <- replicate(100, {
    index_dat <- dat$y %>% createDataPartition(times = 1, p = 0.5, list=FALSE)
    train_dat <- dat %>% slice(-index_dat)
    test_dat <- dat %>% slice(index_dat)
    fit_dat <- lm(y ~ x, data = train_dat)
    y_hat_dat <- predict.lm(fit_dat, test_dat)
    sqrt(mean((y_hat_dat - test_dat$y)^2))
    })
  c(mean(RMSE), sd(RMSE))
})



```

```{r 3.1.Q4}
# set.seed(1) # if using R 3.5 or earlier
set.seed(1, sample.kind="Rounding") # if using R 3.6 or later
n <- 100
Sigma <- 9*matrix(c(1.0, 0.95, 0.95, 1.0), 2, 2)
dat <- MASS::mvrnorm(n = 100, c(69, 69), Sigma) %>%
	data.frame() %>% setNames(c("x", "y"))

my_func <- function() {
  index_dat <- dat$y %>% createDataPartition(times = 1, p = 0.5, list=FALSE)
  train_dat <- dat %>% slice(-index_dat)
  test_dat <- dat %>% slice(index_dat)
  fit_dat <- lm(y ~ x, data = train_dat)
  y_hat_dat <- predict.lm(fit_dat, test_dat)
  sqrt(mean((y_hat_dat - test_dat$y)^2))
}

set.seed(1, sample.kind="Rounding")
RMSE <- replicate(n, my_func())

mean(RMSE)
sd(RMSE)
```

```{r 3.1.Q6}
# set.seed(1) # if using R 3.5 or earlier
set.seed(1, sample.kind="Rounding") # if using R 3.6 or later
Sigma <- matrix(c(1.0, 0.75, 0.75, 0.75, 1.0, 0.25, 0.75, 0.25, 1.0), 3, 3)
dat <- MASS::mvrnorm(n = 100, c(0, 0, 0), Sigma) %>%
	data.frame() %>% setNames(c("y", "x_1", "x_2"))

cor(dat)

set.seed(1, sample.kind="Rounding")
index_dat <- dat$y %>% createDataPartition(times = 1, p = 0.5, list=FALSE)
train_dat <- dat %>% slice(-index_dat)
test_dat <- dat %>% slice(index_dat)

# train model on x_1
fit_dat <- lm(y ~ x_1, data = train_dat)
y_hat_dat <- predict.lm(fit_dat, test_dat)
sqrt(mean((y_hat_dat - test_dat$y)^2))

# train model on x_2
fit_dat <- lm(y ~ x_2, data = train_dat)
y_hat_dat <- predict.lm(fit_dat, test_dat)
sqrt(mean((y_hat_dat - test_dat$y)^2))

# train model on x_1 and x_2
fit_dat <- lm(y ~ x_1 + x_2, data = train_dat)
y_hat_dat <- predict.lm(fit_dat, test_dat)
sqrt(mean((y_hat_dat - test_dat$y)^2))



```


```{r 3.1.Q8}
# set.seed(1) # if using R 3.5 or earlier
set.seed(1, sample.kind="Rounding") # if using R 3.6 or later
Sigma <- matrix(c(1.0, 0.75, 0.75, 0.75, 1.0, 0.95, 0.75, 0.95, 1.0), 3, 3)
dat <- MASS::mvrnorm(n = 100, c(0, 0, 0), Sigma) %>%
	data.frame() %>% setNames(c("y", "x_1", "x_2"))

cor(dat)

set.seed(1, sample.kind="Rounding")
index_dat <- dat$y %>% createDataPartition(times = 1, p = 0.5, list=FALSE)
train_dat <- dat %>% slice(-index_dat)
test_dat <- dat %>% slice(index_dat)

# train model on x_1
fit_dat <- lm(y ~ x_1, data = train_dat)
y_hat_dat <- predict.lm(fit_dat, test_dat)
sqrt(mean((y_hat_dat - test_dat$y)^2))

# train model on x_2
fit_dat <- lm(y ~ x_2, data = train_dat)
y_hat_dat <- predict.lm(fit_dat, test_dat)
sqrt(mean((y_hat_dat - test_dat$y)^2))

# train model on x_1 and x_2
fit_dat <- lm(y ~ x_1 + x_2, data = train_dat)
y_hat_dat <- predict.lm(fit_dat, test_dat)
sqrt(mean((y_hat_dat - test_dat$y)^2))
```


### Section 3.1: Categorical Outcomes & Logistic Regression


```{r}
y <- heights$height
set.seed(2, sample.kind = "Rounding") #if you are using R 3.6 or later

test_index <- createDataPartition(y, times = 1, p = 0.5, list = FALSE)
train_set <- heights %>% slice(-test_index)
test_set <- heights %>% slice(test_index)

train_set %>% 
  filter(round(height)==66) %>%
  summarise(y_hat = mean(sex=="Female"))

lm_fit <- mutate(train_set, y = as.numeric(sex == "Female")) %>% lm(y ~ height, data = .)
p_hat <- predict(lm_fit, test_set)
y_hat <- ifelse(p_hat > 0.5, "Female", "Male") %>% factor()
confusionMatrix(y_hat, test_set$sex)$overall["Accuracy"]

heights %>% 
  mutate(x = round(height)) %>%
  group_by(x) %>%
  filter(n() >= 10) %>%
  summarise(prop = mean(sex == "Female")) %>%
  ggplot(aes(x, prop)) + 
  geom_point() +
  geom_abline(intercept = lm_fit$coef[1], slope = lm_fit$coef[2])

range(p_hat)


# fit logistic regression model

glm_fit <- train_set %>% 
  mutate(y = as.numeric(sex == "Female")) %>%
  glm(y ~ height, data=., family = "binomial")

p_hat_logit <- predict(glm_fit, newdata = test_set, type = "response")

tmp <- heights %>%
  mutate(x = round(height)) %>%
  group_by(x) %>%
  filter(n() >= 10) %>%
  summarise(prop = mean(sex == "Female"))

logistic_curve <- data.frame(x = seq(min(tmp$x), max(tmp$x))) %>%
  mutate(p_hat = plogis(glm_fit$coef[1] + glm_fit$coef[2]*x))

tmp %>%
  ggplot(aes(x, prop)) + 
  geom_point() +
  geom_line(data = logistic_curve, mapping = aes(x, p_hat), lty = 2)
  
```


```{r case_study_2_7}
mnist <- read_mnist()



# largest and smallest x_1
is <- mnist_27$index_train[c(which.min(mnist_27$train$x_1), which.max(mnist_27$train$x_1))]
titles <- c("smallest","largest")

tmp <- lapply(1:2, function(i){
    expand.grid(Row=1:28, Column=1:28) %>%
        mutate(label=titles[i],
               value = mnist$train$images[is[i],])
})

tmp <- Reduce(rbind, tmp)

tmp %>% ggplot(aes(Row, Column, fill=value)) +
    geom_raster() +
    scale_y_reverse() +
    scale_fill_gradient(low="white", high="black") +
    facet_grid(.~label) +
    geom_vline(xintercept = 14.5) +
    geom_hline(yintercept = 14.5)


data("mnist_27")
mnist_27$train %>% ggplot(aes(x_1, x_2, color = y)) + geom_point()



# largest and smallest x_2

is <- mnist_27$index_train[c(which.min(mnist_27$train$x_2), which.max(mnist_27$train$x_2))]
titles <- c("smallest","largest")

tmp <- lapply(1:2, function(i){
    expand.grid(Row=1:28, Column=1:28) %>%
        mutate(label=titles[i],
               value = mnist$train$images[is[i],])
})

tmp <- Reduce(rbind, tmp)

tmp %>% ggplot(aes(Row, Column, fill=value)) +
    geom_raster() +
    scale_y_reverse() +
    scale_fill_gradient(low="white", high="black") +
    facet_grid(.~label) +
    geom_vline(xintercept = 14.5) +
    geom_hline(yintercept = 14.5)


# model fitting

fit_glm <- glm(y ~ x_1 + x_2, data=mnist_27$train, family = "binomial")

p_hat_glm <- predict(fit_glm, mnist_27$test)
y_hat_glm <- factor(ifelse(p_hat_glm > 0.5, 7, 2))
confusionMatrix(data = y_hat_glm, reference = mnist_27$test$y)$overall["Accuracy"]

mnist_27$true_p %>% ggplot(aes(x_1, x_2, fill=p)) +
    geom_raster()


mnist_27$true_p %>% ggplot(aes(x_1, x_2, z=p, fill=p)) +
    geom_raster() +
    scale_fill_gradientn(colors=c("#F8766D","white","#00BFC4")) +
    stat_contour(breaks=c(0.5), color="black") 


p_hat <- predict(fit_glm, newdata = mnist_27$true_p)
mnist_27$true_p %>%
    mutate(p_hat = p_hat) %>%
    ggplot(aes(x_1, x_2,  z=p_hat, fill=p_hat)) +
    geom_raster() +
    scale_fill_gradientn(colors=c("#F8766D","white","#00BFC4")) +
    stat_contour(breaks=c(0.5),color="black") 

p_hat <- predict(fit_glm, newdata = mnist_27$true_p)
mnist_27$true_p %>%
    mutate(p_hat = p_hat) %>%
    ggplot() +
    stat_contour(aes(x_1, x_2, z=p_hat), breaks=c(0.5), color="black") +
    geom_point(mapping = aes(x_1, x_2, color=y), data = mnist_27$test)

```


### Comprehension

```{r 3.1.q1}

# set.seed(2) #if you are using R 3.5 or earlier
set.seed(2, sample.kind="Rounding") #if you are using R 3.6 or later

make_data <- function(n = 1000, p = 0.5, 
				mu_0 = 0, mu_1 = 2, 
				sigma_0 = 1,  sigma_1 = 1){

y <- rbinom(n, 1, p)
f_0 <- rnorm(n, mu_0, sigma_0)
f_1 <- rnorm(n, mu_1, sigma_1)
x <- ifelse(y == 1, f_1, f_0)
  
test_index <- createDataPartition(y, times = 1, p = 0.5, list = FALSE)

list(train = data.frame(x = x, y = as.factor(y)) %>% slice(-test_index),
	test = data.frame(x = x, y = as.factor(y)) %>% slice(test_index))
}
dat <- make_data()


dat$train %>% ggplot(aes(x, color = y)) + geom_density()


set.seed(1, sample.kind="Rounding") #if you are using R 3.6 or later
mu_1 <- seq(0, 3, len=25)

res <- sapply(mu_1, function(mu_1){
  my_dat <- make_data(mu_1 = mu_1)
  my_train <- my_dat$train
  my_test <- my_dat$test
  my_fit <- glm(y ~ x, data=my_train, family = "binomial")
  p_hat <- predict(my_fit, newdat=my_test, type="response")
  y_hat <- factor(ifelse(p_hat > 0.5, 1, 0))
  confusionMatrix(data = y_hat, reference = my_test$y)$overall["Accuracy"]
})

my_q1 <- tibble(mu_1, res)

my_q1 %>% ggplot(aes(x = mu_1, y = res)) + geom_point()


```


### Section 3.2: Smoothing

From textbook: Smoothing is a very powerful technique used all across data analysis. Other names given to this technique are *curve fitting* and *low pass filtering*.

Our goal is to extract the signal from the noise and then use the signal as an improved predictor in our models. The data below presents the trend in the popular vote by examining the margin between Obama and McCain. In extracting the signal we are looking to identify the general trend. Notice that simple linear regression does a poor job of locating this trend.


```{r}
data("polls_2008")
qplot(day, margin, data = polls_2008)


polls_2008 %>% ggplot(aes(day, margin)) + geom_point() + geom_smooth(method = lm)

```

An alternate approach is to use binning which groups data points into strata where the value of f(x) is reasonably assumed to be constant. The size of the interval is referred to as the *window size*, the *bandwidth*, or the *span*. The process of using binning looks at the average within each bin.

```{r}
# bin smoothers
span <- 7 
fit <- with(polls_2008,ksmooth(day, margin, x.points = day, kernel="box", bandwidth =span))
polls_2008 %>% mutate(smooth = fit$y) %>%
    ggplot(aes(day, margin)) +
    geom_point(size = 3, alpha = .5, color = "grey") + 
    geom_line(aes(day, smooth), color="red")
```

Notice as the window moves, there is a high resulting variability in the averages. This is because we some points leaving the window, and new points entering the window as it moves. This can be attenuating using a weighted average approach that focuses on the center of the window. Using weighted averages is also referred to as using a kernel.

```{r}
# kernel
span <- 7
fit <- with(polls_2008, ksmooth(day, margin,  x.points = day, kernel="normal", bandwidth = span))
polls_2008 %>% mutate(smooth = fit$y) %>%
  ggplot(aes(day, margin)) +
  geom_point(size = 3, alpha = .5, color = "grey") + 
  geom_line(aes(day, smooth), color="red")
```

The effectiveness of the bin smoothing approach is fairly dependent on using small windows for the assumption of a constant mean to hold. In this case, the number of data points in each window is very small. An alternate approach can be used in such situations, called local weighted regression. In using LOESS, we instead assume that the smooth function is locally linear (vs. being a constant).

```{r}
polls_2008 %>% ggplot(aes(day, margin)) +
  geom_point() + 
  geom_smooth(color="red", span = 0.15, method = "loess", method.args = list(degree=1))
```

### Comprehension

```{r 3.2.q1}
library(tidyverse)
library(lubridate)
library(purrr)
library(pdftools)
    
fn <- system.file("extdata", "RD-Mortality-Report_2015-18-180531.pdf", package="dslabs")
dat <- map_df(str_split(pdf_text(fn), "\n"), function(s){
	s <- str_trim(s)
	header_index <- str_which(s, "2015")[1]
	tmp <- str_split(s[header_index], "\\s+", simplify = TRUE)
	month <- tmp[1]
	header <- tmp[-1]
	tail_index  <- str_which(s, "Total")
	n <- str_count(s, "\\d+")
	out <- c(1:header_index, which(n==1), which(n>=28), tail_index:length(s))
	s[-out] %>%
		str_remove_all("[^\\d\\s]") %>%
		str_trim() %>%
		str_split_fixed("\\s+", n = 6) %>%
		.[,1:5] %>%
		as_data_frame() %>% 
		setNames(c("day", header)) %>%
		mutate(month = month,
			day = as.numeric(day)) %>%
		gather(year, deaths, -c(day, month)) %>%
		mutate(deaths = as.numeric(deaths))
}) %>%
	mutate(month = recode(month, "JAN" = 1, "FEB" = 2, "MAR" = 3, "APR" = 4, "MAY" = 5, "JUN" = 6, 
                          "JUL" = 7, "AGO" = 8, "SEP" = 9, "OCT" = 10, "NOV" = 11, "DEC" = 12)) %>%
	mutate(date = make_date(year, month, day)) %>%
        dplyr::filter(date <= "2018-05-01")


# remove NA values
dat <- na.omit(dat)

# need to make the span ~2 months long, so need min/max date
total_days <- diff(range(dat$date))
span <- 60/as.numeric(total_days)


# use loess to fit smooth curve on deaths by month

fit <- loess(deaths ~ as.numeric(date), degree = 1, span = span, data = dat, family = "symmetric")

dat %>%
  mutate(smooth = fit$fitted) %>%
  ggplot(aes(date, deaths)) +
  geom_point() +
  geom_line(aes(date, smooth), color="red", size=2)

dat %>% 
  ggplot(aes(date, deaths)) +
  geom_point() +
  geom_smooth(method = "loess", span = 0.05, method.args = list(degree=1), colour = "red", size = 2)

```


```{r 3.2.q2}

dat %>% 
  mutate(smooth = predict(fit, as.numeric(date)), day = yday(date), year = as.character(year(date))) %>%
  ggplot(aes(day, smooth, col = year)) +
  geom_line(lwd=2)
  
```

```{r 3.2.q3}

library(broom)

mnist_27$train %>% mutate(y = as.numeric(levels(mnist_27$train$y))[y]) %>% head()

fitmnist <- mnist_27$train %>% loess(as.numeric(levels(mnist_27$train$y))[y] ~ x_2, family = "symmetric", data = ., degree = 1,)

mnist_27$train %>%
  mutate(smooth = fitmnist$fitted) %>%
  ggplot(aes(x_2, as.numeric(levels(mnist_27$train$y))[y])) +
  geom_point() +
  geom_line(aes(x_2, smooth), color="red", size=2)

# answer
mnist_27$train %>% 
	mutate(y = ifelse(y=="7", 1, 0)) %>%
	ggplot(aes(x_2, y)) + 
	geom_smooth(method = "loess")

```


### Section 3.3: Working with Matrices

```{r}
library(tidyverse)
library(dslabs)
if(!exists("mnist")) mnist <- read_mnist()

class(mnist$train$images)

x <- mnist$train$images[1:1000,] 
y <- mnist$train$labels[1:1000]
```


```{r}
length(x[,1])
x_1 <- 1:5
x_2 <- 6:10
cbind(x_1, x_2)
dim(x)
dim(x_1)
dim(as.matrix(x_1))
dim(x)
```


```{r}
my_vector <- 1:15

# fill the matrix by column
mat <- matrix(my_vector, 5, 3)
mat

# fill by row
mat_t <- matrix(my_vector, 3, 5, byrow = TRUE)
mat_t

identical(t(mat), mat_t)

# note the repeated use of vector values
matrix(my_vector, 5, 5)

# visualize the 3rd entry of the x matrix
grid <- matrix(x[3,], 28, 28)
image(1:28, 1:28, grid)

# flip the image
image(1:28, 1:28, grid[, 28:1])

```

Putting into practice:
- compute the total pixel darkness by summing values of each row and visualizing by digit
- compute the average pixel intensity and examine how it changes by digit

```{r}
sums <- rowSums(x)
avg <- rowMeans(x)

data_frame(labels = as.factor(y), row_averages = avg) %>%
    qplot(labels, row_averages, data = ., geom = "boxplot")

avgs <- apply(x, 1, mean)
sds <- apply(x, 2, sd)

```


```{r}
library(matrixStats)

sds <- colSds(x)
qplot(sds, bins = "30", color = I("black"))
image(1:28, 1:28, matrix(sds, 28, 28)[, 28:1])

#extract columns and rows
x[ ,c(351,352)]
x[c(2,3),]

new_x <- x[ ,colSds(x) > 60]
dim(new_x)
class(x[,1])
dim(x[1,])

#preserve the matrix class
class(x[ , 1, drop=FALSE])
dim(x[, 1, drop=FALSE])

```


```{r}
#index with matrices
mat <- matrix(1:15, 5, 3)
as.vector(mat)
qplot(as.vector(x), bins = 30, color = I("black"))
new_x <- x
new_x[new_x < 50] <- 0

mat <- matrix(1:15, 5, 3)
mat[mat < 3] <- 0
mat

mat <- matrix(1:15, 5, 3)
mat[mat > 6 & mat < 12] <- 0
mat

#binarize the data
bin_x <- x
bin_x[bin_x < 255/2] <- 0
bin_x[bin_x > 255/2] <- 1
bin_X <- (x > 255/2)*1
```


```{r}

#scale each row of a matrix
(x - rowMeans(x)) / rowSds(x)

#scale each column
t(t(x) - colMeans(x))

#take each entry of a vector and subtracts it from the corresponding row or column
x_mean_0 <- sweep(x, 2, colMeans(x))

#divide by the standard deviation
x_mean_0 <- sweep(x, 2, colMeans(x))
x_standardized <- sweep(x_mean_0, 2, colSds(x), FUN = "/")

```


### Comprehension


```{r}
x <- matrix(rnorm(100*10), 100, 10)

dim(x)[1]


x <- mnist$train$images
y <- mnist$train$labels

sum(x > 50 & x < 205) / (60000 * 784)



bin_X <- (x > 50 & x < 205)*1

avg <- apply(x, 1, mean)

data_frame(labels = as.factor(y), row_averages = avg) %>%
    qplot(labels, row_averages, data = ., geom = "boxplot")


```



## Section 4: Distance, KNN, Cross-validation, Generative Models

```{r}
if(!exists("mnist")) mnist <- read_mnist()
set.seed(0) # if using R 3.5 or earlier
set.seed(0, sample.kind = "Rounding") # if using R 3.6 or later
ind <- which(mnist$train$labels %in% c(2,7)) %>% sample(500)

#the predictors are in x and the labels in y
x <- mnist$train$images[ind,]
y <- mnist$train$labels[ind]

y[1:3]

x_1 <- x[1,]
x_2 <- x[2,]
x_3 <- x[3,]

#distance between two numbers
sqrt(sum((x_1 - x_2)^2))
sqrt(sum((x_1 - x_3)^2))
sqrt(sum((x_2 - x_3)^2))

#compute distance using matrix algebra
sqrt(crossprod(x_1 - x_2))
sqrt(crossprod(x_1 - x_3))
sqrt(crossprod(x_2 - x_3))

#compute distance between each row
d <- dist(x)
class(d)
as.matrix(d)[1:3,1:3]

#visualize these distances
image(as.matrix(d))

#order the distance by labels
image(as.matrix(d)[order(y), order(y)])

#compute distance between predictors
d <- dist(t(x))
dim(as.matrix(d))

d_492 <- as.matrix(d)[492,]

image(1:28, 1:28, matrix(d_492, 28, 28))

```


```{r}
library(dslabs)
data(tissue_gene_expression)

dim(tissue_gene_expression$x)

table(tissue_gene_expression$y)

x <- tissue_gene_expression$x
y <- tissue_gene_expression$y
d <- dist(x)

image(1:100, 1:100, as.matrix(d)[1:100, 1:100])
image(as.matrix(d))

```

### KNN Algorithm


```{r}
x <- as.matrix(mnist_27$train[,2:3])
y <- mnist_27$train$y

#logistic regression
library(caret)
fit_glm <- glm(y~x_1+x_2, data=mnist_27$train, family="binomial")
p_hat_logistic <- predict(fit_glm, mnist_27$test)
y_hat_logistic <- factor(ifelse(p_hat_logistic > 0.5, 7, 2))
confusionMatrix(data = y_hat_logistic, reference = mnist_27$test$y)$overall[1]

#fit knn model
knn_fit <- knn3(y ~ ., data = mnist_27$train)

x <- as.matrix(mnist_27$train[,2:3])
y <- mnist_27$train$y
knn_fit <- knn3(x, y)

knn_fit <- knn3(y ~ ., data = mnist_27$train, k=5)

y_hat_knn <- predict(knn_fit, mnist_27$test, type = "class")
confusionMatrix(data = y_hat_knn, reference = mnist_27$test$y)$overall["Accuracy"]


```



```{r}
y_hat_knn <- predict(knn_fit, mnist_27$train, type = "class") 
confusionMatrix(data = y_hat_knn, reference = mnist_27$train$y)$overall["Accuracy"]
y_hat_knn <- predict(knn_fit, mnist_27$test, type = "class")  
confusionMatrix(data = y_hat_knn, reference = mnist_27$test$y)$overall["Accuracy"]

#fit knn with k=1
knn_fit_1 <- knn3(y ~ ., data = mnist_27$train, k = 1)
y_hat_knn_1 <- predict(knn_fit_1, mnist_27$train, type = "class")
confusionMatrix(data=y_hat_knn_1, reference=mnist_27$train$y)$overall[["Accuracy"]]

y_hat_knn_1 <- predict(knn_fit_1, mnist_27$test, type = "class")
confusionMatrix(data=y_hat_knn_1, reference=mnist_27$test$y)$overall[["Accuracy"]]

#fit knn with k=401
knn_fit_401 <- knn3(y ~ ., data = mnist_27$train, k = 401)
y_hat_knn_401 <- predict(knn_fit_401, mnist_27$test, type = "class")
confusionMatrix(data=y_hat_knn_401, reference=mnist_27$test$y)$overall["Accuracy"]

#pick the k in knn
ks <- seq(3, 251, 2)
library(purrr)
accuracy <- map_df(ks, function(k){
    fit <- knn3(y ~ ., data = mnist_27$train, k = k)

    y_hat <- predict(fit, mnist_27$train, type = "class")
    cm_train <- confusionMatrix(data = y_hat, reference = mnist_27$train$y)
    train_error <- cm_train$overall["Accuracy"]
    
    y_hat <- predict(fit, mnist_27$test, type = "class")
    cm_test <- confusionMatrix(data = y_hat, reference = mnist_27$test$y)
    f1_score <- f_meas(cm_test)
    test_error <- cm_test$overall["Accuracy"]
    
    tibble(train = train_error, test = test_error)
    
})

#pick the k that maximizes accuracy using the estimates built on the test data
ks[which.max(accuracy$test)]
max(accuracy$test)

```

### Comprehension


```{r}

y = heights$sex
set.seed(1, sample.kind = "Rounding") #if you are using R 3.6 or later

test_index <- createDataPartition(y, times = 1, p = 0.5, list = FALSE)
train_set <- heights %>% slice(-test_index)
test_set <- heights %>% slice(test_index)

ks <- seq(1, 101, 3)

accuracy <- map_df(ks, function(k){
    fit <- knn3(sex ~ ., data = train_set, k = k)

    y_hat <- predict(fit, train_set, type = "class")
    cm_train <- confusionMatrix(data = y_hat, reference = train_set$sex)
    f1_train <- F_meas(data = y_hat, reference = train_set$sex)
    train_error <- cm_train$overall["Accuracy"]
    
    y_hat <- predict(fit, test_set, type = "class")
    cm_test <- confusionMatrix(data = y_hat, reference = test_set$sex)
    f1_test <- F_meas(data = y_hat, reference = test_set$sex)
    test_error <- cm_test$overall["Accuracy"]
    
    tibble(k = k, train = f1_train, test = f1_test)

})

accuracy

ks[which.max(accuracy$test)]
max(accuracy$test)

cbind(k = ks, accuracy) %>% 
  pivot_longer(!k, names_to = "data", values_to = "Score")  %>%
  ggplot(aes(k, Score, color = data)) + geom_point()

```

```{r}
data("tissue_gene_expression")
y = tissue_gene_expression$y
x = tissue_gene_expression$x

set.seed(1, sample.kind="Rounding")
test_index <- createDataPartition(y, times = 1, p = 0.5, list = FALSE)

train_set_x <- x[-test_index,]
train_set_y <- y[-test_index]

test_set_x <- x[test_index,]
test_set_y <- y[test_index]

ks = seq(1, 11, 2)

accuracy <- map_df(ks, function(k){
    fit <- knn3(train_set_x, train_set_y, k = k)

    y_hat <- predict(fit, train_set_x, type = "class")
    cm_train <- confusionMatrix(data = y_hat, reference = train_set_y)
    #f1_train <- F_meas(data = y_hat, reference = train_set$y)c
    
    y_hat <- predict(fit, test_set_x, type = "class")
    cm_test <- confusionMatrix(data = y_hat, reference = test_set_y)
    #f1_test <- F_meas(data = y_hat, reference = test_set$y)
    test_error <- cm_test$overall["Accuracy"]
    
    tibble(k = k, train = train_error, test = test_error)

})


accuracy

ks[which.max(accuracy$test)]
max(accuracy$test)

cbind(k = ks, accuracy) %>% 
  pivot_longer(!k, names_to = "data", values_to = "Score")  %>%
  ggplot(aes(k, Score, color = data)) + geom_point()


```

### Cross-Validation


```{r}
# set.seed(1996) #if you are using R 3.5 or earlier
set.seed(1996, sample.kind="Rounding") #if you are using R 3.6 or later
n <- 1000
p <- 10000
x <- matrix(rnorm(n*p), n, p)
colnames(x) <- paste("x", 1:ncol(x), sep = "_")
y <- rbinom(n, 1, 0.5) %>% factor()

x_subset <- x[ ,sample(p, 100)]

fit <- train(x_subset, y, method = "glm")
fit$results

```



```{r}
install.packages("BiocManager")
BiocManager::install("genefilter")
library(genefilter)
tt <- colttests(x, y)


pvals <- tt$p.value
ind <- pvals <= 0.01
ind
sum(ind)

x_subset <- x[ ,ind]
fit <- train(x_subset, y, method = "glm")
fit$results


fit <- train(x_subset, y, method = "knn", tuneGrid = data.frame(k = seq(101, 301, 25)))
ggplot(fit)

```



```{r}

y = tissue_gene_expression$y
x = tissue_gene_expression$x

fit <- train(x, y, method = "knn", tuneGrid = data.frame(k = seq(1, 7, 2)))
ggplot(fit)

```

### Bootstrapping

```{r}
n <- 10^6
income <- 10^(rnorm(n, log10(45000), log10(3)))
qplot(log10(income), bins = 30, color = I("black"))

m <- median(income)
m

set.seed(1)
#use set.seed(1, sample.kind="Rounding") instead if using R 3.6 or later
N <- 250
X <- sample(income, N)
M<- median(X)
M

library(gridExtra)
B <- 10^5
M <- replicate(B, {
    X <- sample(income, N)
    median(X)
})
p1 <- qplot(M, bins = 30, color = I("black"))
p2 <- qplot(sample = scale(M)) + geom_abline()
grid.arrange(p1, p2, ncol = 2)

mean(M)
sd(M)

B <- 10^5
M_star <- replicate(B, {
    X_star <- sample(X, N, replace = TRUE)
    median(X_star)
})

tibble(monte_carlo = sort(M), bootstrap = sort(M_star)) %>%
    qplot(monte_carlo, bootstrap, data = .) + 
    geom_abline()

quantile(M, c(0.05, 0.95))
quantile(M_star, c(0.05, 0.95))

median(X) + 1.96 * sd(X) / sqrt(N) * c(-1, 1)

mean(M) + 1.96 * sd(M) * c(-1,1)

mean(M_star) + 1.96 * sd(M_star) * c(-1, 1)

```



```{r}

library(dslabs)
library(caret)
data(mnist_27)
# set.seed(1995) # if R 3.5 or earlier
set.seed(1995, sample.kind="Rounding") # if R 3.6 or later
indexes <- createResample(mnist_27$train$y, 10)

sum(indexes$Resample01 == 7)

sum(sapply(indexes, function(n){sum(n == 3)}))



set.seed(1)

B <- 10000
Y_star <- replicate(B, {
  y <- rnorm(100, 0, 1)
  quantile(y, 0.75)
})

mean(Y_star)
sd(Y_star)

```


```{r}
N = 100

set.seed(1, sample.kind = "Rounding")
y <- rnorm(N, 0, 1)

set.seed(1, sample.kind = "Rounding")

B <- 10
M_star <- replicate(B, {
    Y_star <- sample(y, N, replace = TRUE)
    quantile(Y_star, 0.75)
})

mean(M_star)
sd(M_star)



set.seed(1, sample.kind = "Rounding")

B <- 10000
M_star <- replicate(B, {
    Y_star <- sample(y, N, replace = TRUE)
    quantile(Y_star, 0.75)
})

mean(M_star)
sd(M_star)



```


### Generative Models


```{r}
# Generating train and test set
library("caret")
data("heights")
y <- heights$height
set.seed(2)
test_index <- createDataPartition(y, times = 1, p = 0.5, list = FALSE)
train_set <- heights %>% slice(-test_index)
test_set <- heights %>% slice(test_index)

# Estimating averages and standard deviations
params <- train_set %>%
 group_by(sex) %>%
 summarise(avg = mean(height), sd = sd(height))
params

# Estimating the prevalence
pi <- train_set %>% summarise(pi=mean(sex=="Female")) %>% pull(pi)
pi

# Getting an actual rule
x <- test_set$height
f0 <- dnorm(x, params$avg[2], params$sd[2])
f1 <- dnorm(x, params$avg[1], params$sd[1])
p_hat_bayes <- f1*pi / (f1*pi + f0*(1 - pi))

```

```{r}
# Computing sensitivity
y_hat_bayes <- ifelse(p_hat_bayes > 0.5, "Female", "Male")
sensitivity(data = factor(y_hat_bayes), reference = factor(test_set$sex))

# Computing specificity
specificity(data = factor(y_hat_bayes), reference = factor(test_set$sex))

# Changing the cutoff of the decision rule
p_hat_bayes_unbiased <- f1 * 0.5 / (f1 * 0.5 + f0 * (1 - 0.5))
y_hat_bayes_unbiased <- ifelse(p_hat_bayes_unbiased > 0.5, "Female", "Male")
sensitivity(data = factor(y_hat_bayes_unbiased), reference = factor(test_set$sex))
specificity(data = factor(y_hat_bayes_unbiased), reference = factor(test_set$sex))

# Draw plot
qplot(x, p_hat_bayes_unbiased, geom = "line") +
 geom_hline(yintercept = 0.5, lty = 2) +
 geom_vline(xintercept = 67, lty = 2)

```


Quadratic discriminant analysis (QDA) is a version of Naive Bayes in which we assume that the conditional distributions are multivariate normal. 

QDA can work well with a few predictors, but it becomes harder to use as the number of predictors increases. Once the number of parameters approaches the size of our data, the method becomes impractical due to overfitting.

```{r}
# Load data
data("mnist_27")

# Estimate parameters from the data
params <- mnist_27$train %>%
 group_by(y) %>%
 summarise(avg_1 = mean(x_1), avg_2 = mean(x_2),
        sd_1 = sd(x_1), sd_2 = sd(x_2),
        r = cor(x_1, x_2))

# Contour plots
mnist_27$train %>% mutate(y = factor(y)) %>%
 ggplot(aes(x_1, x_2, fill = y, color = y)) +
 geom_point(show.legend = FALSE) +
 stat_ellipse(type="norm", lwd = 1.5)

# Fit model
library(caret)
train_qda <- train(y ~., method = "qda", data = mnist_27$train)
# Obtain predictors and accuracy
y_hat <- predict(train_qda, mnist_27$test)
confusionMatrix(data = y_hat, reference = mnist_27$test$y)$overall["Accuracy"]

# Draw separate plots for 2s and 7s
mnist_27$train %>% mutate(y = factor(y)) %>%
 ggplot(aes(x_1, x_2, fill = y, color = y)) +
 geom_point(show.legend = FALSE) +
 stat_ellipse(type="norm") +
 facet_wrap(~y)
```

Forcing the assumption that all predictors share the same standard deviations and correlations, the boundary will be a line, just as with logistic regression. For this reason, we call the method linear discriminant analysis (LDA).

```{r}
params <- mnist_27$train %>%
 group_by(y) %>%
 summarize(avg_1 = mean(x_1), avg_2 = mean(x_2),
        sd_1 = sd(x_1), sd_2 = sd(x_2),
        r = cor(x_1, x_2))
params <- params %>% mutate(sd_1 = mean(sd_1), sd_2 = mean(sd_2), r = mean(r))
train_lda <- train(y ~., method = "lda", data = mnist_27$train)
y_hat <- predict(train_lda, mnist_27$test)
confusionMatrix(data = y_hat, reference = mnist_27$test$y)$overall["Accuracy"]
```




```{r}
if(!exists("mnist"))mnist <- read_mnist()

set.seed(3456)    #use set.seed(3456, sample.kind="Rounding") in R 3.6 or later
index_127 <- sample(which(mnist$train$labels %in% c(1,2,7)), 2000)
y <- mnist$train$labels[index_127] 
x <- mnist$train$images[index_127,]
index_train <- createDataPartition(y, p=0.8, list = FALSE)

# get the quadrants
# temporary object to help figure out the quadrants
row_column <- expand.grid(row=1:28, col=1:28)
upper_left_ind <- which(row_column$col <= 14 & row_column$row <= 14)
lower_right_ind <- which(row_column$col > 14 & row_column$row > 14)

# binarize the values. Above 200 is ink, below is no ink
x <- x > 200 

# cbind proportion of pixels in upper right quadrant and proportion of pixels in lower right quadrant
x <- cbind(rowSums(x[ ,upper_left_ind])/rowSums(x),
           rowSums(x[ ,lower_right_ind])/rowSums(x)) 

train_set <- data.frame(y = factor(y[index_train]),
                        x_1 = x[index_train,1],
                        x_2 = x[index_train,2])

test_set <- data.frame(y = factor(y[-index_train]),
                       x_1 = x[-index_train,1],
                       x_2 = x[-index_train,2])

train_set %>%  ggplot(aes(x_1, x_2, color=y)) + geom_point()

train_qda <- train(y ~ ., method = "qda", data = train_set)
predict(train_qda, test_set, type = "prob") %>% head()
predict(train_qda, test_set) %>% head()

confusionMatrix(predict(train_qda, test_set), test_set$y)$table
confusionMatrix(predict(train_qda, test_set), test_set$y)$overall["Accuracy"]

train_lda <- train(y ~ ., method = "lda", data = train_set)
confusionMatrix(predict(train_lda, test_set), test_set$y)$overall["Accuracy"]

train_knn <- train(y ~ ., method = "knn", tuneGrid = data.frame(k = seq(15, 51, 2)),
    data = train_set)
confusionMatrix(predict(train_knn, test_set), test_set$y)$overall["Accuracy"]

train_set %>% mutate(y = factor(y)) %>% ggplot(aes(x_1, x_2, fill = y, color=y)) + geom_point(show.legend = FALSE) + stat_ellipse(type="norm")

```



### Comprehension

```{r}

library(dslabs)
library(caret)
library(tidyverse)
data("tissue_gene_expression")
      
# set.seed(1993) #if using R 3.5 or earlier
set.seed(1993, sample.kind="Rounding") # if using R 3.6 or later
ind <- which(tissue_gene_expression$y %in% c("cerebellum", "hippocampus"))
y <- droplevels(tissue_gene_expression$y[ind])
x <- tissue_gene_expression$x[ind, ]
x <- x[, sample(ncol(x), 10)]
xy <- data.frame(y = y, x = x)

train_lda <- train(y ~ ., method = "lda", data = xy)

train_lda$finalModel$means




library(dslabs)      
library(caret)
data("tissue_gene_expression")
      
set.seed(1993) #set.seed(1993, sample.kind="Rounding") if using R 3.6 or later
ind <- which(tissue_gene_expression$y %in% c("cerebellum", "hippocampus"))
y <- droplevels(tissue_gene_expression$y[ind])
x <- tissue_gene_expression$x[ind, ]
x <- x[, sample(ncol(x), 10)]

xy <- data.frame(y = y, x = x)

train_qda <- train(y ~ ., method = "qda", data = xy)

train_qda

train_qda$finalModel$means



library(dslabs)
library(caret)
library(tidyverse)
data("tissue_gene_expression")
      
# set.seed(1993) #if using R 3.5 or earlier
set.seed(1993, sample.kind="Rounding") # if using R 3.6 or later
ind <- which(tissue_gene_expression$y %in% c("cerebellum", "hippocampus"))
y <- droplevels(tissue_gene_expression$y[ind])
x <- tissue_gene_expression$x[ind, ]
x <- x[, sample(ncol(x), 10)]
xy <- data.frame(y = y, x = x)

train_lda <- train(y ~ ., method = "lda", data = xy, preProcess = "center")

train_lda

train_lda$finalModel$means




library(dslabs)      
library(caret)
data("tissue_gene_expression")
           
# set.seed(1993) # if using R 3.5 or earlier
set.seed(1993, sample.kind="Rounding") # if using R 3.6 or later
y <- tissue_gene_expression$y
x <- tissue_gene_expression$x
x <- x[, sample(ncol(x), 10)]


xy <- data.frame(y = y, x = x)

train_lda <- train(y ~ ., method = "lda", data = xy)

train_lda

train_lda$finalModel$means

```


## Classification & Regression Trees



```{r}
# Load data
library(tidyverse)
library(dslabs)
data("olive")
olive %>% as_tibble()
table(olive$region)
olive <- select(olive, -area)

# Predict region using KNN
library(caret)
fit <- train(region ~ .,  method = "knn", 
             tuneGrid = data.frame(k = seq(1, 15, 2)), 
             data = olive)
ggplot(fit)

# Plot distribution of each predictor stratified by region
olive %>% gather(fatty_acid, percentage, -region) %>%
  ggplot(aes(region, percentage, fill = region)) +
  geom_boxplot() +
  facet_wrap(~fatty_acid, scales = "free") +
  theme(axis.text.x = element_blank())

# plot values for eicosenoic and linoleic
p <- olive %>% 
  ggplot(aes(eicosenoic, linoleic, color = region)) + 
  geom_point()
p + geom_vline(xintercept = 0.065, lty = 2) + 
  geom_segment(x = -0.2, y = 10.54, xend = 0.065, yend = 10.54, color = "black", lty = 2)

# load data for regression tree
data("polls_2008")
qplot(day, margin, data = polls_2008)

library(rpart)
fit <- rpart(margin ~ ., data = polls_2008)

# visualize the splits 
plot(fit, margin = 0.1)
text(fit, cex = 0.75)
polls_2008 %>% 
  mutate(y_hat = predict(fit)) %>% 
  ggplot() +
  geom_point(aes(day, margin)) +
  geom_step(aes(day, y_hat), col="red")

# change parameters
fit <- rpart(margin ~ ., data = polls_2008, control = rpart.control(cp = 0, minsplit = 2))
polls_2008 %>% 
  mutate(y_hat = predict(fit)) %>% 
  ggplot() +
  geom_point(aes(day, margin)) +
  geom_step(aes(day, y_hat), col="red")

# use cross validation to choose cp
library(caret)
train_rpart <- train(margin ~ ., method = "rpart", tuneGrid = data.frame(cp = seq(0, 0.05, len = 25)), data = polls_2008)
ggplot(train_rpart)

# access the final model and plot it
plot(train_rpart$finalModel, margin = 0.1)
text(train_rpart$finalModel, cex = 0.75)
polls_2008 %>% 
  mutate(y_hat = predict(train_rpart)) %>% 
  ggplot() +
  geom_point(aes(day, margin)) +
  geom_step(aes(day, y_hat), col="red")

# prune the tree 
pruned_fit <- prune(fit, cp = 0.01)

```


```{r}
# fit a classification tree and plot it
train_rpart <- train(y ~ .,
              method = "rpart",
              tuneGrid = data.frame(cp = seq(0.0, 0.1, len = 25)),
              data = mnist_27$train)
plot(train_rpart)

# compute accuracy
confusionMatrix(predict(train_rpart, mnist_27$test), mnist_27$test$y)$overall["Accuracy"]

```



```{r}
library(randomForest)
fit <- randomForest(margin~., data = polls_2008) 
plot(fit)

polls_2008 %>%
  mutate(y_hat = predict(fit, newdata = polls_2008)) %>% 
  ggplot() +
  geom_point(aes(day, margin)) +
  geom_line(aes(day, y_hat), col="red")

library(randomForest)
train_rf <- randomForest(y ~ ., data=mnist_27$train)
confusionMatrix(predict(train_rf, mnist_27$test), mnist_27$test$y)$overall["Accuracy"]

# use cross validation to choose parameter
train_rf_2 <- train(y ~ .,
      method = "Rborist",
      tuneGrid = data.frame(predFixed = 2, minNode = c(3, 50)),
      data = mnist_27$train)
confusionMatrix(predict(train_rf_2, mnist_27$test), mnist_27$test$y)$overall["Accuracy"]

```



```{r}
library(randomForest)
fit <- randomForest(margin~., data = polls_2008) 
plot(fit)

polls_2008 %>%
  mutate(y_hat = predict(fit, newdata = polls_2008)) %>% 
  ggplot() +
  geom_point(aes(day, margin)) +
  geom_line(aes(day, y_hat), col="red")

library(randomForest)
train_rf <- randomForest(y ~ ., data=mnist_27$train)
confusionMatrix(predict(train_rf, mnist_27$test), mnist_27$test$y)$overall["Accuracy"]

# use cross validation to choose parameter
train_rf_2 <- train(y ~ .,
      method = "Rborist",
      tuneGrid = data.frame(predFixed = 2, minNode = c(3, 50)),
      data = mnist_27$train)
confusionMatrix(predict(train_rf_2, mnist_27$test), mnist_27$test$y)$overall["Accuracy"]

```



```{r}
library(rpart)
n <- 1000
sigma <- 0.25
# set.seed(1) # if using R 3.5 or ealier
set.seed(1, sample.kind = "Rounding") # if using R 3.6 or later
x <- rnorm(n, 0, 1)
y <- 0.75 * x + rnorm(n, 0, sigma)
dat <- data.frame(x = x, y = y)

fit <- rpart(y ~ ., data = dat)

par(xpd = TRUE)
plot(fit, compress = TRUE)
text(fit)
```



```{r}

dat %>% 
	mutate(y_hat = predict(fit)) %>% 
	ggplot() +
	geom_point(aes(x, y)) +
	geom_step(aes(x, y_hat), col=2)
  
```



```{r}

library(randomForest)
fit <- randomForest(y ~ x, data = dat)  
dat %>% 
	mutate(y_hat = predict(fit)) %>% 
	ggplot() +
	geom_point(aes(x, y)) +
	geom_step(aes(x, y_hat), col = "red")

plot(fit)

```



```{r}
library(randomForest)
fit <- randomForest(y ~ x, data = dat, nodesize = 50, maxnodes = 25)  
dat %>% 
	mutate(y_hat = predict(fit)) %>% 
	ggplot() +
	geom_point(aes(x, y)) +
	geom_step(aes(x, y_hat), col = "red")

plot(fit)

```

### Caret Package


```{r}
library(tidyverse)
library(dslabs)
data("mnist_27")

library(caret)
train_glm <- train(y ~ ., method = "glm", data = mnist_27$train)
train_knn <- train(y ~ ., method = "knn", data = mnist_27$train)

y_hat_glm <- predict(train_glm, mnist_27$test, type = "raw")
y_hat_knn <- predict(train_knn, mnist_27$test, type = "raw")

confusionMatrix(y_hat_glm, mnist_27$test$y)$overall[["Accuracy"]]
confusionMatrix(y_hat_knn, mnist_27$test$y)$overall[["Accuracy"]]

```



```{r}

getModelInfo("knn")
modelLookup("knn")

train_knn <- train(y ~ ., method = "knn", data = mnist_27$train)
ggplot(train_knn, highlight = TRUE)

train_knn <- train(y ~ ., method = "knn", 
                   data = mnist_27$train,
                   tuneGrid = data.frame(k = seq(9, 71, 2)))
ggplot(train_knn, highlight = TRUE)
train_knn$bestTune
train_knn$finalModel
confusionMatrix(predict(train_knn, mnist_27$test, type = "raw"),
                mnist_27$test$y)$overall["Accuracy"]

control <- trainControl(method = "cv", number = 10, p = .9)
train_knn_cv <- train(y ~ ., method = "knn", 
                      data = mnist_27$train,
                      tuneGrid = data.frame(k = seq(9, 71, 2)),
                      trControl = control)
ggplot(train_knn_cv, highlight = TRUE)

train_knn$results %>% 
     ggplot(aes(x = k, y = Accuracy)) +
     geom_line() +
     geom_point() +
     geom_errorbar(aes(x = k, 
                       ymin = Accuracy - AccuracySD,
                       ymax = Accuracy + AccuracySD))

plot_cond_prob <- function(p_hat=NULL){
     tmp <- mnist_27$true_p
     if(!is.null(p_hat)){
          tmp <- mutate(tmp, p=p_hat)
     }
     tmp %>% ggplot(aes(x_1, x_2, z=p, fill=p)) +
     geom_raster(show.legend = FALSE) +
          scale_fill_gradientn(colors=c("#F8766D","white","#00BFC4")) +
          stat_contour(breaks=c(0.5),color="black")
}

plot_cond_prob(predict(train_knn, mnist_27$true_p, type = "prob")[,2])

install.packages("gam")
modelLookup("gamLoess")

grid <- expand.grid(span = seq(0.15, 0.65, len = 10), degree = 1)

train_loess <- train(y ~ ., 
               method = "gamLoess",
               tuneGrid=grid,
               data = mnist_27$train)
ggplot(train_loess, highlight = TRUE)

confusionMatrix(data = predict(train_loess, mnist_27$test), 
                reference = mnist_27$test$y)$overall["Accuracy"]

p1 <- plot_cond_prob(predict(train_loess, mnist_27$true_p, type = "prob")[,2])
p1

```



```{r}
# set.seed(1993) #if using R 3.5 or earlier
set.seed(1991, sample.kind="Rounding") # if using R 3.6 or later

y <- droplevels(tissue_gene_expression$y)
x <- tissue_gene_expression$x
xy <- data.frame(y = y, x = x)


train_rpart <- train(y ~ ., method = "rpart", data = xy, tuneGrid = data.frame(cp = seq(0, 0.1, 0.01)))
train_rpart

set.seed(1991, sample.kind="Rounding") # if using R 3.6 or later
train_rpart <- train(y ~ ., method = "rpart", data = xy, tuneGrid = data.frame(cp = seq(0, 0.1, 0.01)), control = rpart.control(minsplit = 0))



```



```{r}
plot(train_rpart$finalModel)
text(train_rpart$finalModel)
```

```{r}

set.seed(1991, sample.kind="Rounding") # if using R 3.6 or later
train_rf <- train(y ~ ., method = "rf", data = xy, tuneGrid = data.frame(mtry = seq(50, 200, 25)), nodesize = 1)
train_rf


imp <- varImp(train_rf)

tree_terms <- as.character(unique(train_rpart$finalModel$frame$var[!(train_rpart$finalModel$frame$var == "<leaf>")]))



```


```{r titanic}
library(titanic)    # loads titanic_train data frame
library(caret)
library(tidyverse)
library(rpart)

# 3 significant digits
options(digits = 3)

# clean the data - `titanic_train` is loaded with the titanic package
titanic_clean <- titanic_train %>%
    mutate(Survived = factor(Survived),
           Embarked = factor(Embarked),
           Age = ifelse(is.na(Age), median(Age, na.rm = TRUE), Age), # NA age to median age
           FamilySize = SibSp + Parch + 1) %>%    # count family members
    select(Survived,  Sex, Pclass, Age, Fare, SibSp, Parch, FamilySize, Embarked)

set.seed(42, sample.kind="Rounding") # if using R 3.6 or later
test_index <- createDataPartition(titanic_clean$Survived, times = 1, p = 0.2, list = FALSE)
train_set <- titanic_clean %>% slice(-test_index)
test_set <- titanic_clean %>% slice(test_index)

sum(train_set$Survived=="1") / length(train_set$Survived)

set.seed(3, sample.kind="Rounding") # if using R 3.6 or later
y_hat <- sample(c(0,1), length(test_set$Survived), replace=TRUE) %>% factor()
confusionMatrix(y_hat, test_set$Survived)$overall["Accuracy"]


train_set %>% group_by(Sex, Survived) %>% summarise(n = n()) %>% mutate(p = n/sum(n))

y_hat <- test_set %>% mutate(Survived = ifelse(Sex == "male", 0, 1)) %>% pull(Survived) %>% factor()
confusionMatrix(y_hat, test_set$Survived)$overall["Accuracy"]
confusionMatrix(y_hat, test_set$Survived)
F_meas(data = y_hat, reference = test_set$Survived)


train_set %>% group_by(Pclass, Survived) %>% summarise(n = n()) %>% mutate(p = n/sum(n))
y_hat <- test_set %>% mutate(Survived = ifelse(Pclass == 1, 1, 0)) %>% pull(Survived) %>% factor()
confusionMatrix(y_hat, test_set$Survived)$overall["Accuracy"]
confusionMatrix(y_hat, test_set$Survived)
F_meas(data = y_hat, reference = test_set$Survived)

train_set %>% group_by(Sex, Pclass, Survived) %>% summarise(n = n()) %>% mutate(p = n/sum(n)) %>% filter(p > 0.5)
y_hat <- test_set %>% mutate(Survived = ifelse(Sex == "female" & Pclass %in% c(1,2), 1, 0)) %>% pull(Survived) %>% factor()
confusionMatrix(y_hat, test_set$Survived)$overall["Accuracy"]
confusionMatrix(y_hat, test_set$Survived)
F_meas(data = y_hat, reference = test_set$Survived)


```



```{r}

set.seed(1, sample.kind="Rounding") # if using R 3.6 or later
train_fit <- train(Survived ~ Fare, method = "lda", data = train_set )
train_fit

y_hat <- predict(train_fit, test_set)
confusionMatrix(data = y_hat, reference = test_set$Survived)$overall["Accuracy"]


set.seed(1, sample.kind="Rounding") # if using R 3.6 or later
train_fit <- train(Survived ~ Fare, method = "qda", data = train_set, na.action = na.fail, contrasts = NULL, weights = NULL)
train_fit

y_hat <- predict(train_fit, test_set)
confusionMatrix(data = y_hat, reference = test_set$Survived)$overall["Accuracy"]


set.seed(1, sample.kind="Rounding") # if using R 3.6 or later
train_fit <- glm(Survived ~ Age, data = train_set, family = "binomial")
train_fit

p_hat <- predict(train_fit, newdata = test_set, type = "response")
y_hat <- factor(ifelse(p_hat > 0.5, 1, 0))
confusionMatrix(data = y_hat, reference = test_set$Survived)$overall["Accuracy"]


set.seed(1, sample.kind="Rounding") # if using R 3.6 or later
train_fit <- glm(Survived ~ Age + Sex + Pclass + Fare, data = train_set, family = "binomial")
train_fit

p_hat <- predict(train_fit, newdata = test_set, type = "response")
y_hat <- factor(ifelse(p_hat > 0.5, 1, 0))
confusionMatrix(data = y_hat, reference = test_set$Survived)$overall["Accuracy"]



set.seed(1, sample.kind="Rounding") # if using R 3.6 or later
train_fit <- glm(Survived ~ ., data = train_set, family = "binomial")
train_fit

p_hat <- predict(train_fit, newdata = test_set, type = "response")
y_hat <- factor(ifelse(p_hat > 0.5, 1, 0))
confusionMatrix(data = y_hat, reference = test_set$Survived)$overall["Accuracy"]


```



```{r}

set.seed(6, sample.kind="Rounding")
train_fit <- train(Survived ~ ., method = "knn", 
                   data = train_set,
                   tuneGrid = data.frame(k = seq(3, 51, 2)))
ggplot(train_fit, highlight = TRUE)

train_fit
train_fit$bestTune
train_fit$finalModel
confusionMatrix(predict(train_fit, test_set, type = "raw"),
                test_set$Survived)$overall["Accuracy"]

```


```{r}
set.seed(8, sample.kind="Rounding")
fitControl <- trainControl(## 10-fold CV
                           method = "repeatedcv",
                           number = 10,
                           ## repeated ten times
                           repeats = 1,
                           ## partition size
                           p = 0.90)

train_fit <- train(Survived ~ ., method = "knn", 
                   data = train_set,
                   tuneGrid = data.frame(k = seq(3, 51, 2)),
                   trControl = fitControl)
ggplot(train_fit, highlight = TRUE)

train_fit
train_fit$bestTune
train_fit$finalModel
confusionMatrix(predict(train_fit, test_set, type = "raw"),
                test_set$Survived)$overall["Accuracy"]





```


```{r}
set.seed(10, sample.kind="Rounding")
train_fit <- train(Survived ~ ., method = "rpart", 
                   data = train_set,
                   tuneGrid = data.frame(cp = seq(0, 0.05, 0.002)))

train_fit
confusionMatrix(predict(train_fit, test_set, type = "raw"),
                test_set$Survived)$overall["Accuracy"]

plot(train_fit$finalModel)
text(train_fit$finalModel)

```


```{r}
set.seed(14, sample.kind="Rounding")
train_fit <- train(Survived ~ ., method = "rf", 
                   data = train_set,
                   tuneGrid = data.frame(mtry = seq(1:7)),
                   ntree = 100)

train_fit
confusionMatrix(predict(train_fit, test_set, type = "raw"),
                test_set$Survived)$overall["Accuracy"]

varImp(train_fit)

```

## Case Study


```{r}
library(dslabs)
mnist <- read_mnist()

names(mnist)
dim(mnist$train$images)

class(mnist$train$labels)
table(mnist$train$labels)

# sample 10k rows from training set, 1k rows from test set
set.seed(123)
index <- sample(nrow(mnist$train$images), 10000)
x <- mnist$train$images[index,]
y <- factor(mnist$train$labels[index])

index <- sample(nrow(mnist$test$images), 1000)
#note that the line above is the corrected code - code in video at 0:52 is incorrect
x_test <- mnist$test$images[index,]
y_test <- factor(mnist$test$labels[index])


library(matrixStats)
sds <- colSds(x)
qplot(sds, bins = 256, color = I("black"))

library(caret)
nzv <- nearZeroVar(x)
image(matrix(1:784 %in% nzv, 28, 28))

col_index <- setdiff(1:ncol(x), nzv)
length(col_index)


```


```{r}
colnames(x) <- 1:ncol(mnist$train$images)
colnames(x_test) <- colnames(x)

control <- trainControl(method = "cv", number = 10, p = .9)
train_knn <- train(x[,col_index], y,
                                method = "knn", 
                                tuneGrid = data.frame(k = c(1,3,5,7)),
                                trControl = control)
ggplot(train_knn)

n <- 1000
b <- 2
index <- sample(nrow(x), n)
control <- trainControl(method = "cv", number = b, p = .9)
train_knn <- train(x[index ,col_index], y[index],
                   method = "knn",
                   tuneGrid = data.frame(k = c(3,5,7)),
                   trControl = control)
fit_knn <- knn3(x[ ,col_index], y,  k = 3)

y_hat_knn <- predict(fit_knn,
                     x_test[, col_index],
                     type="class")
cm <- confusionMatrix(y_hat_knn, factor(y_test))
cm$overall["Accuracy"]

cm$byClass[,1:2]

library(Rborist)
control <- trainControl(method="cv", number = 5, p = 0.8)
grid <- expand.grid(minNode = c(1,5) , predFixed = c(10, 15, 25, 35, 50))
train_rf <-  train(x[, col_index], y,
                   method = "Rborist",
                   nTree = 50,
                   trControl = control,
                   tuneGrid = grid,
                   nSamp = 5000)
ggplot(train_rf)
train_rf$bestTune

fit_rf <- Rborist(x[, col_index], y,
                  nTree = 1000,
                  minNode = train_rf$bestTune$minNode,
                  predFixed = train_rf$bestTune$predFixed)

y_hat_rf <- factor(levels(y)[predict(fit_rf, x_test[ ,col_index])$yPred])
cm <- confusionMatrix(y_hat_rf, y_test)
cm$overall["Accuracy"]

rafalib::mypar(3,4)
for(i in 1:12){
     image(matrix(x_test[i,], 28, 28)[, 28:1], 
           main = paste("Our prediction:", y_hat_rf[i]),
           xaxt="n", yaxt="n")
}

```


```{r}
library(randomForest)
x <- mnist$train$images[index,]
y <- factor(mnist$train$labels[index])
rf <- randomForest(x, y,  ntree = 50)
imp <- importance(rf)
imp

image(matrix(imp, 28, 28))

p_max <- predict(fit_knn, x_test[,col_index])
p_max <- apply(p_max, 1, max)
ind  <- which(y_hat_knn != y_test)
ind <- ind[order(p_max[ind], decreasing = TRUE)]
rafalib::mypar(3,4)
for(i in ind[1:12]){
    image(matrix(x_test[i,], 28, 28)[, 28:1],
                 main = paste0("Pr(",y_hat_knn[i],")=",round(p_max[i], 2),
                                                                        " but is a ",y_test[i]),
                 xaxt="n", yaxt="n")
}

p_max <- predict(fit_rf, x_test[,col_index])$census  
p_max <- p_max / rowSums(p_max)
p_max <- apply(p_max, 1, max)
ind  <- which(y_hat_rf != y_test)
ind <- ind[order(p_max[ind], decreasing = TRUE)]
rafalib::mypar(3,4)
for(i in ind[1:12]){
    image(matrix(x_test[i,], 28, 28)[, 28:1], 
                 main = paste0("Pr(",y_hat_rf[i],")=",round(p_max[i], 2),
                               " but is a ",y_test[i]),
                 xaxt="n", yaxt="n")
}

```

### Ensembles

```{r}

p_rf <- predict(fit_rf, x_test[,col_index])$census
p_rf <- p_rf / rowSums(p_rf)
p_knn <- predict(fit_knn, x_test[,col_index])
p <- (p_rf + p_knn)/2
y_pred <- factor(apply(p, 1, which.max)-1)
confusionMatrix(y_pred, y_test)
```

### Comprehension

```{r}
models <- c("glm", "lda", "naive_bayes", "svmLinear", "knn", "gamLoess", "multinom", "qda", "rf", "adaboost")


library(caret)
library(dslabs)
library(tidyverse)
# set.seed(1) # if using R 3.5 or earlier
set.seed(1, sample.kind = "Rounding") # if using R 3.6 or later
data("mnist_27")

fits <- lapply(models, function(model){ 
	print(model)
	train(y ~ ., method = model, data = mnist_27$train)
}) 
    
names(fits) <- models

y_hats <- map(fits, function(fit) {
  predict(fit, newdata = mnist_27$test)
  })


c_matrix <- sapply(y_hats, function(preds) {
  confusionMatrix(preds, mnist_27$test$y)$overall["Accuracy"]
  }
  )

y_hats <- sapply(fits, function(fit) {
  predict(fit, newdata = mnist_27$test)
  })

y_hat <- factor(apply(y_hats, 1, function(x) {
  ifelse(sum(x == "7") >= 3, 7, 2)
}))

confusionMatrix(y_hat, mnist_27$test$y)$overall["Accuracy"]

```



```{r}
fits_acc <- sapply(fits, function(model){
  model$results$Accuracy[1]
  })

fits_acc >= 0.8
fits2 <- fits[fits_acc >= 0.8]
fits2

y_hats <- sapply(fits2, function(fit) {
  predict(fit, newdata = mnist_27$test)
  })

y_hat <- factor(apply(y_hats, 1, function(x) {
  ifelse(sum(x == "7") > 5, 7, 2)
}))

confusionMatrix(y_hat, mnist_27$test$y)$overall["Accuracy"]
```



```{r}
library(dslabs)
library(tidyverse)
data("movielens")

head(movielens)

movielens %>%
     summarize(n_users = n_distinct(userId),
               n_movies = n_distinct(movieId))

keep <- movielens %>%
     dplyr::count(movieId) %>%
     top_n(5) %>%
     pull(movieId)
tab <- movielens %>%
     filter(userId %in% c(13:20)) %>% 
     filter(movieId %in% keep) %>% 
     select(userId, title, rating) %>% 
     spread(title, rating)
tab %>% knitr::kable()

users <- sample(unique(movielens$userId), 100)
rafalib::mypar()
movielens %>% filter(userId %in% users) %>% 
     select(userId, movieId, rating) %>%
     mutate(rating = 1) %>%
     spread(movieId, rating) %>% select(sample(ncol(.), 100)) %>% 
     as.matrix() %>% t(.) %>%
     image(1:100, 1:100,. , xlab="Movies", ylab="Users")
abline(h=0:100+0.5, v=0:100+0.5, col = "grey")

movielens %>% 
     dplyr::count(movieId) %>% 
     ggplot(aes(n)) + 
     geom_histogram(bins = 30, color = "black") + 
     scale_x_log10() + 
     ggtitle("Movies")

movielens %>%
     dplyr::count(userId) %>% 
     ggplot(aes(n)) + 
     geom_histogram(bins = 30, color = "black") + 
     scale_x_log10() +
     ggtitle("Users")

library(caret)
set.seed(755)
test_index <- createDataPartition(y = movielens$rating, times = 1,
                                  p = 0.2, list = FALSE)
train_set <- movielens[-test_index,]
test_set <- movielens[test_index,]

test_set <- test_set %>% 
     semi_join(train_set, by = "movieId") %>%
     semi_join(train_set, by = "userId")

RMSE <- function(true_ratings, predicted_ratings){
     sqrt(mean((true_ratings - predicted_ratings)^2))
}

```



```{r}
mu_hat <- mean(train_set$rating)
mu_hat

naive_rmse <- RMSE(test_set$rating, mu_hat)
naive_rmse

predictions <- rep(2.5, nrow(test_set))
RMSE(test_set$rating, predictions)

rmse_results <- data_frame(method = "Just the average", RMSE = naive_rmse)

# fit <- lm(rating ~ as.factor(userId), data = movielens)
mu <- mean(train_set$rating) 
movie_avgs <- train_set %>% 
     group_by(movieId) %>% 
     summarize(b_i = mean(rating - mu))

movie_avgs %>% qplot(b_i, geom ="histogram", bins = 10, data = ., color = I("black"))

predicted_ratings <- mu + test_set %>% 
     left_join(movie_avgs, by='movieId') %>%
     .$b_i

model_1_rmse <- RMSE(predicted_ratings, test_set$rating)
rmse_results <- bind_rows(rmse_results,
                          data_frame(method="Movie Effect Model",
                                     RMSE = model_1_rmse ))

rmse_results %>% knitr::kable()

train_set %>% 
     group_by(userId) %>% 
     summarize(b_u = mean(rating)) %>% 
     filter(n()>=100) %>%
     ggplot(aes(b_u)) + 
     geom_histogram(bins = 30, color = "black")

# lm(rating ~ as.factor(movieId) + as.factor(userId))
user_avgs <- test_set %>% 
     left_join(movie_avgs, by='movieId') %>%
     group_by(userId) %>%
     summarize(b_u = mean(rating - mu - b_i))

predicted_ratings <- test_set %>% 
     left_join(movie_avgs, by='movieId') %>%
     left_join(user_avgs, by='userId') %>%
     mutate(pred = mu + b_i + b_u) %>%
     .$pred

model_2_rmse <- RMSE(predicted_ratings, test_set$rating)
rmse_results <- bind_rows(rmse_results,
                          data_frame(method="Movie + User Effects Model",  
                                     RMSE = model_2_rmse ))
rmse_results %>% knitr::kable()

```

## Recommender Systems

Key ideas
- we want to recommend movies to users based on other users who have similar tastes
- some users have rated significantly more movies than others
- some movies have significantly more user ratings than others
- we need to define a loss function

```{r}
library(tidyverse)
library(lubridate)
library(dslabs)
data("movielens")

movielens %>% head()
movielens %>% group_by(year) %>% summarise(n = n()) %>% arrange(by_group=n)
movielens %>% filter(title == "The Shawshank Redemption" & !is.na(rating)) %>% summarise(avg = mean(rating))

movielens %>% 
  group_by(title) %>% 
  summarise(n=n()) %>%
  ggplot(aes(x = n)) + 
  geom_bar(stat="bin", position=position_dodge(), color="black", fill="grey") + 
  scale_x_log10() + 
  ggtitle("Movies")

movielens %>% 
     dplyr::count(movieId) %>% 
     ggplot(aes(n)) + 
     geom_histogram(bins = 30, color = "black") + 
     scale_x_log10() + 
     ggtitle("Movies")

movielens %>% 
  group_by(userId) %>% 
  summarise(n=n()) %>% 
  ggplot(aes(x=n)) + 
  geom_bar(stat="bin", position=position_dodge(), color="black", fill="grey") + 
  scale_x_log10() + 
  ggtitle("Users")

movielens %>%
     dplyr::count(userId) %>% 
     ggplot(aes(n)) + 
     geom_histogram(bins = 30, color = "black") + 
     scale_x_log10() +
     ggtitle("Users")

```

Notice that we will have a significant number of NAs for user ratings across the many movies.


```{r}
# select 5 movies to gather data on
keep <- movielens %>%
     dplyr::count(movieId) %>%
     top_n(5) %>%
     pull(movieId)

# spread the data so each movie has its own column with rows as users and entries being user ratings for each movie
tab <- movielens %>%
     filter(userId %in% c(13:20)) %>% 
     filter(movieId %in% keep) %>% 
     select(userId, title, rating) %>% 
     spread(title, rating)

# show the table, formatted
tab %>% knitr::kable()

```



```{r}
# select 100 users at random
users <- sample(unique(movielens$userId), 100)

# create a plot of indcators for each user and rating combination
movielens %>% filter(userId %in% users) %>% 
     select(userId, movieId, rating) %>%
     mutate(rating = 1) %>%
     spread(movieId, rating) %>% select(sample(ncol(.), 100)) %>% 
     as.matrix() %>% t(.) %>%
     image(1:100, 1:100,. , xlab="Movies", ylab="Users")
abline(h=0:100+0.5, v=0:100+0.5, col = "grey")

```

Partition our data into train and test sets ensuring that test set only includes users and movies that exist in the training data. Define an error function based on the RMSE of actual vs. predicted raings.

```{r}
library(caret)
set.seed(755)
test_index <- createDataPartition(y = movielens$rating, times = 1,
                                  p = 0.2, list = FALSE)
train_set <- movielens[-test_index,]
test_set <- movielens[test_index,]

test_set <- test_set %>% 
     semi_join(train_set, by = "movieId") %>%
     semi_join(train_set, by = "userId")

RMSE <- function(true_ratings, predicted_ratings){
     sqrt(mean((true_ratings - predicted_ratings)^2))
}

```

Let's start with a naive model where we assume the actual rating is simply the average rating across all movies.

```{r}

mu <- mean(train_set$rating)
mu

naive_rmse <- RMSE(test_set$rating, mu_hat)
naive_rmse

rmse_results <- tibble(method = "Just the average", RMSE = naive_rmse)

```

What if we now consider that each movie as an average rating across all users that deviates from the global average. We can model this using simply regression. Note that using LM to fit a regression model will take a considerable amount of time due to the volume of data.

```{r}
#fit <- lm(rating ~ as.factor(movieId), data = movielens)

movie_avgs <- train_set %>% 
  group_by(movieId) %>%
  summarise(b_i = mean(rating - mu))

qplot(b_i, data = movie_avgs, bins = 10, color = I("black"))



predicted_ratings <- mu + test_set %>% left_join(movie_avgs, by = "movieId") %>% pull(b_i)

RMSE(predicted_ratings, test_set$rating)

model_1_rmse <- RMSE(predicted_ratings, test_set$rating)
rmse_results <- bind_rows(rmse_results,
                          data_frame(method="Movie Effect Model",
                                     RMSE = model_1_rmse ))
```



Now let's consider the impact of individual users on the ratings, but let's also filter on users who have rated 100 or more titles.

```{r}

train_set %>% 
  group_by(userId) %>% 
  filter(n()>=100) %>%
  summarise(b_u = mean(rating)) %>% 
  ggplot(aes(b_u)) + 
  geom_histogram(bins = 30, color = "black")


user_avgs <- train_set %>%
  left_join(movie_avgs, by = "movieId") %>%
  group_by(userId) %>%
  summarise(b_u = mean(rating - mu - b_i))

predicted_ratings <- test_set %>% 
  left_join(movie_avgs, by='movieId') %>%
  left_join(user_avgs, by='userId') %>%
  mutate(pred = mu + b_i + b_u) %>%
  pull(pred)

RMSE(predicted_ratings, test_set$rating)
model_2_rmse <- RMSE(predicted_ratings, test_set$rating)
rmse_results <- bind_rows(rmse_results,
                          data_frame(method="Movie + User Effects Model",  
                                     RMSE = model_2_rmse ))
rmse_results %>% knitr::kable()
```


### Comprehension

```{r}
library(tidyverse)
library(lubridate)
library(dslabs)
library(stringr)
library(rbin)
data("movielens")


movielens %>% filter(movieId %in% movielens$movieId[str_detect(movielens$title, "demption$")])

movielens %>% select(timestamp) %>% mutate(date = as_datetime(timestamp)) %>% mutate(rateyear = year(date))

movielens %>% 
  filter(year > 1993 & year < 2019) %>%
  mutate(date = as_datetime(timestamp)) %>% 
  mutate(rateyear = year(date)) %>%
  group_by(title) %>%
  summarise(n=n(), AverageRating = mean(rating)) %>%
  mutate(RatingsPerYear = n / 24) %>%
  arrange(desc(RatingsPerYear)) %>%
  slice(1:25)

mydata <- movielens %>% 
  filter(year > 1993 & year < 2019) %>%
  mutate(date = as_datetime(timestamp)) %>% 
  mutate(rateyear = year(date)) %>%
  group_by(title) %>%
  summarise(n=n(), AverageRating = mean(rating)) %>%
  mutate(RatingsPerYear = n / 24) %>%
  arrange(desc(RatingsPerYear))


mydata %>% ggplot(aes(x = RatingsPerYear, y =AverageRating)) + geom_point()



movielens %>% 
  mutate(week = round_date(as_datetime(timestamp),"week")) %>% 
  group_by(week) %>% 
  summarise(avgRating = mean(rating)) %>%
  ggplot(aes(x=week,y=avgRating)) + geom_point()
  
  
movielens %>%
  group_by(genres) %>%
  summarise(n=n()) %>%
  filter(n > 1000) %>% 
  left_join(movielens, by = "genres") %>%
  group_by(genres) %>%
  summarise(avgRating = mean(rating), sdRating = sd(rating)) %>%
  arrange(avgRating)
  

```

### Regularization

Here are the cases with the largest mistakes in our prediction set.

```{r}

test_set %>% 
  left_join(movie_avgs, by='movieId') %>%
  mutate(residual = rating - (mu + b_i)) %>%
  arrange(desc(abs(residual))) %>%  
  slice(1:10) %>% 
  pull(title)

```

Let's look at how many ratings exist for the best and worst movies in our prediction set.

```{r}
movie_titles <- movielens %>% 
  select(movieId, title) %>%
  distinct()


test_set %>%
  count(movieId) %>%
  left_join(movie_avgs, by='movieId') %>%
  left_join(movie_titles, by="movieId") %>%
  arrange(desc(b_i)) %>%
  slice(1:10)
  
test_set %>%
  count(movieId) %>%
  left_join(movie_avgs, by='movieId') %>%
  left_join(movie_titles, by="movieId") %>%
  arrange(b_i) %>%
  slice(1:10)


```

We can use regularization to constrain estimates for b_i in cases where we have a limited number of ratings for a given movie. In these cases, it is better to produce an estimate b_i close to zero such that we predict the overall mean rating for a movie with few ratings.

We can compare the estimates using the two methodologies.

```{r}

# choose a lambda parameter
lambda <- 3
mu <- mean(train_set$rating)

# compute the regularized parameter estimate for b_i
movie_reg_avgs <- train_set %>% 
  group_by(movieId) %>%
  summarise(b_i = sum(rating - mu) / (lambda + n()), n_i = n())

# plot the regularized estimate against the original estimate
# notice the lower degree of dispersion when using the penalty term in coming up with our LSE
tibble(original = movie_avgs$b_i,
       regularized = movie_reg_avgs$b_i,
       n = movie_reg_avgs$n_i) %>%
  ggplot(aes(original, regularized, size=sqrt(n))) +
  geom_point(shape = 1, alpha = 0.5) +
  ylim(-3,1.5)

```



We can apply the same regularization method more broadly to the user bias parameter as well.

```{r}

lambda <- 3
mu <- mean(train_set$rating)

b_i <- train_set %>% 
  group_by(movieId) %>%
  summarise(b_i = sum(rating - mu) / (lambda + n()))

b_u <- train_set %>%
  left_join(b_i, by = "movieId") %>%
  group_by(userId) %>%
  summarise(b_u = sum(rating - mu - b_i) / (lambda + n()))

predicted_ratings <- test_set %>%
  left_join(b_i, by = "movieId") %>%
  left_join(b_u, by = "userId") %>%
  mutate(pred = mu + b_i + b_u, residual = rating - pred)

RMSE(predicted_ratings$pred, test_set$rating)

predicted_ratings %>% ggplot(aes(pred,rating)) + geom_point() + ggtitle("Predicted vs. Actual")

predicted_ratings %>% ggplot(aes(pred,residual)) + geom_point() + ggtitle("Residuals")

movie_bias_pred <- function(lambda){
  mu <- mean(train_set$rating)
  b_i <- train_set %>% group_by(movieId) %>% summarise(b_i = sum(rating - mu) / (lambda + n()))
  predicted <- test_set %>% left_join(b_i, by = "movieId") %>% mutate(pred = mu + b_i)
  RMSE(predicted$pred, test_set$rating)
  }

lambda_vec <- seq(1,5,0.25)

# plot RMSE against lambda values
tibble(lambda = lambda_vec,
       RMSE = sapply(lambda_vec, movie_bias_pred)) %>%
  ggplot(aes(lambda, RMSE)) + geom_point()

# lambda which minimizes RMSE for movie bias is 3
lambda_movie <- 3

user_bias_pred <- function(lambda){
  b_i_lambda <- 3
  mu <- mean(train_set$rating)
  b_i <- train_set %>% group_by(movieId) %>% summarise(b_i = sum(rating - mu) / (b_i_lambda + n()))
  b_u <- train_set %>% left_join(b_i, by = "movieId") %>% group_by(userId) %>% summarise(b_u = sum(rating - mu - b_i) / (lambda + n()))
  predicted <- test_set %>% left_join(b_i, by = "movieId") %>% left_join(b_u, by = "userId") %>% mutate(pred = mu + b_i + b_u)
  RMSE(predicted$pred, test_set$rating)
}

lambda_vec <- seq(0.25,4,0.25)

tibble(lambda = lambda_vec,
       RMSE = sapply(lambda_vec, user_bias_pred)) %>%
  ggplot(aes(lambda, RMSE)) + geom_point()

# lambda which minimizes RMSE for user bias is 2.25
lambda_user <- 2.25

# update prediction with optimized estimates

b_i <- train_set %>% 
  group_by(movieId) %>%
  summarise(b_i = sum(rating - mu) / (lambda_movie + n()))

b_u <- train_set %>%
  left_join(b_i, by = "movieId") %>%
  group_by(userId) %>%
  summarise(b_u = sum(rating - mu - b_i) / (lambda_user + n()))

predicted_ratings <- test_set %>%
  left_join(b_i, by = "movieId") %>%
  left_join(b_u, by = "userId") %>%
  mutate(pred = mu + b_i + b_u, residual = rating - pred)

RMSE(predicted_ratings$pred, test_set$rating)

predicted_ratings %>% ggplot(aes(pred,rating)) + geom_point() + ggtitle("Predicted vs. Actual")

predicted_ratings %>% ggplot(aes(pred,residual)) + geom_point() + ggtitle("Residuals")

```

### Comprehension

```{r}
options(digits=7)

# set.seed(1986) # if using R 3.5 or earlier
set.seed(1986, sample.kind="Rounding") # if using R 3.6 or later
n <- round(2^rnorm(1000, 8, 1))


# set.seed(1) # if using R 3.5 or earlier
set.seed(1, sample.kind="Rounding") # if using R 3.6 or later
mu <- round(80 + 2*rt(1000, 5))
range(mu)
schools <- data.frame(id = paste("PS",1:1000),
                      size = n,
                      quality = mu,
                      rank = rank(-mu))

```




### Matrix Factorization

```{r}

train_small <- movielens %>% 
  group_by(movieId) %>%
  filter(n() >= 50 | movieId == 3252) %>% ungroup() %>% 
  group_by(userId) %>%
  filter(n() >= 50) %>% ungroup()

y <- train_small %>% 
  select(userId, movieId, rating) %>%
  pivot_wider(names_from = "movieId", values_from = "rating") %>%
  as.matrix()

rownames(y)<- y[,1]
y <- y[,-1]

movie_titles <- movielens %>% 
  select(movieId, title) %>%
  distinct()

colnames(y) <- with(movie_titles, title[match(colnames(y), movieId)])

y <- sweep(y, 2, colMeans(y, na.rm=TRUE))
y <- sweep(y, 1, rowMeans(y, na.rm=TRUE))



m_1 <- "Godfather, The"
m_2 <- "Godfather: Part II, The"
p1 <- qplot(y[ ,m_1], y[,m_2], xlab = m_1, ylab = m_2)

m_1 <- "Godfather, The"
m_3 <- "Goodfellas"
p2 <- qplot(y[ ,m_1], y[,m_3], xlab = m_1, ylab = m_3)

m_4 <- "You've Got Mail" 
m_5 <- "Sleepless in Seattle" 
p3 <- qplot(y[ ,m_4], y[,m_5], xlab = m_4, ylab = m_5)

gridExtra::grid.arrange(p1, p2 ,p3, ncol = 3)


x <- y[, c(m_1, m_2, m_3, m_4, m_5)]
short_names <- c("Godfather", "Godfather2", "Goodfellas",
                 "You've Got", "Sleepless")
colnames(x) <- short_names
cor(x, use="pairwise.complete")


```


```{r}
library(ggrepel)

y[is.na(y)] <- 0
pca <- prcomp(y)

dim(pca$rotation) # principle components
dim(pca$x) # user effects


qplot(1:nrow(x), pca$sdev, xlab = "PC")


y2 <- tibble(Name = rownames(pca$rotation), as.tibble(pca$rotation[,1:2]))
y2 %>% slice(1:100) %>% ggplot(aes(PC1, PC2)) + geom_point() + geom_label_repel(aes(label = Name),
                  box.padding   = 0.35, 
                  point.padding = 0.5,
                  segment.color = 'grey50') +
  theme_classic()
```


### Comprehension

```{r}
set.seed(1987, sample.kind="Rounding")
n <- 100
k <- 8
Sigma <- 64  * matrix(c(1, .75, .5, .75, 1, .5, .5, .5, 1), 3, 3) 
m <- MASS::mvrnorm(n, rep(0, 3), Sigma)
m <- m[order(rowMeans(m), decreasing = TRUE),]
y <- m %x% matrix(rep(1, k), nrow = 1) + matrix(rnorm(matrix(n*k*3)), n, k*3)
colnames(y) <- c(paste(rep("Math",k), 1:k, sep="_"),
                 paste(rep("Science",k), 1:k, sep="_"),
                 paste(rep("Arts",k), 1:k, sep="_"))

my_image <- function(x, zlim = range(x), ...){
	colors = rev(RColorBrewer::brewer.pal(9, "RdBu"))
	cols <- 1:ncol(x)
	rows <- 1:nrow(x)
	image(cols, rows, t(x[rev(rows),,drop=FALSE]), xaxt = "n", yaxt = "n",
			xlab="", ylab="",  col = colors, zlim = zlim, ...)
	abline(h=rows + 0.5, v = cols + 0.5)
	axis(side = 1, cols, colnames(x), las = 2)
}

my_image(y)


my_image(cor(y), zlim = c(-1,1))
range(cor(y))
axis(side = 2, 1:ncol(y), rev(colnames(y)), las = 2)


s <- svd(y)
names(s)


ss_y <- colSums(y^2)
ss_yv <- colSums((y%*%s$v)^2)
sum(ss_y)
sum(ss_yv)

class(ss_y)
ggplot(tibble(SumSquares = ss_y, ClassID = seq(1,24,1)), aes(ClassID, SumSquares)) + geom_point()
ggplot(tibble(SumSquares = ss_yv, ClassID = seq(1,24,1)), aes(ClassID, SumSquares)) + geom_point()


cumsum(ss_yv / sum(ss_yv))


# visualize that ud1 captures the explanatory component of student averages being generally consistent across subjects
tibble(AverageScore = rowMeans(y), Ud1 = sweep(s$u, 2, s$d, FUN="*")[,1]) %>% ggplot(aes(AverageScore, Ud1)) + geom_point()


# this image of the SVD matrix V shows the relatively constant value for the first component
my_image(s$v)


# let's examine the first component; note that the residuals demonstrate that some correlations remain
plot(s$u[,1], ylim=c(-0.25,0.25))
plot(s$v[,1], ylim=c(-0.25,0.25))

with(s, my_image((u[,1,drop=F] * d[1]) %*% t(v[,1,drop=F])))
my_image(y)

with(s, my_image(u[,1:3,drop=F] %*% diag(d[1:3]) %*% t(v[,1:3,drop=F])))
my_image(y)

resid <- y - with(s,(u[, 1, drop=FALSE]*d[1]) %*% t(v[, 1, drop=FALSE]))
my_image(cor(resid), zlim = c(-1,1))
axis(side = 2, 1:ncol(y), rev(colnames(y)), las = 2)

# we can repeat the exercise for the second and third components
plot(s$u[,2], ylim=c(-0.25,0.25))
plot(s$v[,2], ylim=c(-0.25,0.25))

with(s, my_image((u[,2,drop=F] * d[2]) %*% t(v[,2,drop=F])))
my_image(resid)

resid <- y - with(s,sweep(u[, 1:2], 2, d[1:2], FUN="*") %*% t(v[, 1:2]))
my_image(cor(resid), zlim = c(-1,1))
axis(side = 2, 1:ncol(y), rev(colnames(y)), las = 2)



plot(s$u[,3], ylim=c(-0.25,0.25))
plot(s$v[,3], ylim=c(-0.25,0.25))

with(s, my_image((u[,3,drop=F] * d[3]) %*% t(v[,3,drop=F])))
my_image(resid)

y_hat <- with(s,sweep(u[, 1:3], 2, d[1:3], FUN="*") %*% t(v[, 1:3]))
my_image(y, zlim = range(y))
my_image(y_hat, zlim = range(y))
my_image(y - y_hat, zlim = range(y))




```

```{r}

data("tissue_gene_expression")

# see that we have 500 predictors
dim(tissue_gene_expression$x)
length(tissue_gene_expression$y)
rownames(tissue_gene_expression$x)
colnames(tissue_gene_expression$x)


colMeans(tissue_gene_expression$x)

# extract the principle components using SVD factorization
s <- svd(tissue_gene_expression$x)
dim(s$u)
dim(s$v)

length(s$v[,1])

pca <- prcomp(tissue_gene_expression$x)
summary(pca)

data.frame(pca$x[,1:2], TissueType=tissue_gene_expression$y) %>% 
  ggplot(aes(PC1,PC2, fill = TissueType))+
  geom_point(cex=3, pch=21) +
  coord_fixed(ratio = 1)

data.frame(Means = rowMeans(tissue_gene_expression$x),
           PCA = pca$x[,1],
           TissueType=tissue_gene_expression$y) %>%
  ggplot(aes(Means, PCA, fill = TissueType)) +
  geom_point(cex=3, pch=21)

my_image(cor(rowMeans(tissue_gene_expression$x), pca$x[,1]), zlim = c(-1,1))



cor(rowMeans(tissue_gene_expression$x), pca$x[,1])


# perform clustering 
x <- tissue_gene_expression$x
rownames(x) <- tissue_gene_expression$y
d <- dist(x)
h <- hclust(d)
plot(h, cex = 0.65, main = "", xlab = "")



library(RColorBrewer)
sds <- matrixStats::colSds(tissue_gene_expression$x)
ind <- order(sds, decreasing = TRUE)[1:50]
colors <- brewer.pal(7, "Dark2")[as.numeric(tissue_gene_expression$y)]
heatmap(t(tissue_gene_expression$x[,ind]), col=brewer.pal(11,"RdBu"), scale="row", ColSideColors = colors)

```

```{r}

set.seed(1988)
library(MASS)
n <- 100
Sigma <- matrix(c(9, 9 * 0.9, 9 * 0.92, 9 * 1), 2, 2)
x <- rbind(mvrnorm(n / 2, c(69, 69), Sigma),
           mvrnorm(n / 2, c(55, 55), Sigma))

plot(dist(x), dist(x[,1]))
abline(a=0,b=1, col="red")

z = sqrt(dist(x[,1])^2+dist(x[,2])^2)

z = dist(x[,1])
plot(z, dist(x)/sqrt(2))
abline(a=0,b=1, col="red")


z = dist(x[,2])
plot(z, dist(x)/sqrt(2))
abline(a=0,b=1, col="red")

z  <- cbind((x[,2] + x[,1])/2,  x[,2] - x[,1])

plot(dist(x), dist(z)*sqrt(2))
abline(a=0,b=1, col="red")



z[,1] <- (x[,1] + x[,2]) / sqrt(2)
z[,2] <- (x[,2] - x[,1]) / sqrt(2)

max(dist(z) - dist(x))
sd(dist(x) - dist(z[,1]))

qplot(z[,1], bins = 20, color = I("black"))


pca <- prcomp(x)
data.frame(pca$rotation) %>% ggplot(aes(PC1, PC2)) + geom_point()


```

```{r}

data("movielens")
top <- movielens %>%
  group_by(movieId) %>%
  summarise(n=n(), title = first(title)) %>%
  top_n(50, n) %>%
  pull(movieId)


x <- movielens %>% 
  filter(movieId %in% top) %>%
  group_by(userId) %>%
  filter(n() >= 25) %>%
  ungroup() %>% 
  dplyr::select(c(title, userId, rating)) %>%
  spread(userId, rating)

row_names <- str_remove(x$title, ": Episode") %>% str_trunc(20)
x <- x[,-1] %>% as.matrix()
x <- sweep(x, 2, colMeans(x, na.rm = TRUE))
x <- sweep(x, 1, rowMeans(x, na.rm = TRUE))
rownames(x) <- row_names

d <- dist(x)
h <- hclust(d)
plot(h, cex = 0.65, main = "", xlab = "")

groups <- cutree(h, k = 10)
names(groups)[groups==4]
names(groups)[groups==9]


h_2 <- dist(t(x)) %>% hclust()
plot(h_2, cex = 0.65, main = "", xlab = "")

```

```{r}
options(digits = 3)
library(matrixStats)
library(tidyverse)
library(caret)
library(dslabs)
data(brca)

?brca


# 569 benign or malignant masses and associated features (measurements)

# features: mean, sd, and worst value for 10 nuclear parameters
head(brca$x)

# samples that are malignant
mean(brca$y == "M")

# column with the highest mean
round(apply(brca$x, 2, mean),2)

# column with lowest sd
round(apply(brca$x, 2, sd),4)

# center and scale the columns
x <- sweep(sweep(brca$x, 2, apply(brca$x, 2, mean)), 2, apply(brca$x, 2, sd), FUN="/")
sd(x[,1])
median(x[,1])

x_centered <- sweep(brca$x, 2, colMeans(brca$x))
x_scaled <- sweep(x_centered, 2, colSds(brca$x), FUN = "/")
dim(as.matrix(x_scaled))

# create a heatmap of the features
d_features <- dist(t(x_scaled))
heatmap(as.matrix(d_features), labRow = NA, labCol = NA)

# apply hierarchical clustering to the features
h <- hclust(d_features)
plot(h, cex = 0.65, main = "", xlab = "")
groups <- cutree(h, k = 5)
groups



# PCA
pca <- prcomp(x_scaled)
data.frame(pca$x[,1:2], 
           Class = brca$y) %>% ggplot(aes(PC1, PC2, color=Class)) + geom_point()

data.frame(pca$x[,1:2], type = brca$y) %>%
  ggplot(aes(PC1, PC2, color = type)) +
  geom_point()
        
x_svd <- svd(x_scaled)
x_pca <- prcomp(x_scaled, center = FALSE)

# proving the relationship between svd and pca
x_d <- diag(x_svd$d)
x_d2 <- (x_d %*% x_d) / (length(x[,1]) - 1)
sqrt(x_d2[1,1])
x_s <- diag(x_pca$sdev)
x_s[1,1]


library(reshape)

as.data.frame(melt(data.frame(x_pca$x,
           Class = brca$y),
     id=c("Class"))) %>% 
  ggplot(aes(x=variable, y=value, fill=Class)) + geom_boxplot()


# set.seed(1) if using R 3.5 or earlier
set.seed(1, sample.kind = "Rounding")    # if using R 3.6 or later
test_index <- createDataPartition(brca$y, times = 1, p = 0.2, list = FALSE)
test_x <- x_scaled[test_index,]
test_y <- brca$y[test_index]
train_x <- x_scaled[-test_index,]
train_y <- brca$y[-test_index]


mean(train_y == "B")
mean(test_y == "B")


# k-means clustering applied to brca data set

predict_kmeans <- function(x, k) {
    centers <- k$centers    # extract cluster centers
    # calculate distance to cluster centers
    distances <- sapply(1:nrow(x), function(i){
                        apply(centers, 1, function(y) dist(rbind(x[i,], y)))
                 })
  max.col(-t(distances))  # select cluster with min distance to center
}

k <- kmeans(train_x, 2)
pred_x <- recode(predict_kmeans(test_x, k), "1" = "B", "2" = "M")
mean((pred_x == test_y)[test_y == "B"])
mean((pred_x == test_y)[test_y == "M"])


#### calculate Silhouette statistic for k-means cluster
library(cluster)
x_dist <- dist(train_x)
for(i in 2:10) {
  k <- kmeans(train_x, i)
  print(paste("Cluster #:", i, "Silhouette:", round(mean(silhouette(k$cluster, x_dist)[,3]),4)))
}


library("factoextra")
set.seed(3)
fviz_nbclust(train_x, kmeans, method='silhouette', k.max=21)
set.seed(3)
k <- kmeans(train_x, 3)
fviz_cluster(k, data=train_x)

ggplot() +
  geom_point(data = iris_cluster, 
             mapping = aes(x = Sepal.Length, 
                                  y = Petal.Length, 
                                  colour = cluster))


pca <- prcomp(train_x, scale. = TRUE)

data.frame(pca$x[,1:2], 
           Cluster = k$cluster) %>% ggplot(aes(PC1, PC2, color=Cluster)) + geom_point()
data.frame(pca$x[,1:2], 
           Class = train_y) %>% ggplot(aes(PC1, PC2, color=Class)) + geom_point()


# logistic regression applied to brca data set

library(caret)
x_log <- caret::train(x = train_x,
                      y = train_y,
                      method = "glm",
                      family="binomial")

summary(x_log)
mean(predict(x_log, newdata = test_x, type = "raw") == test_y)

# LDA/QDA
x_lda <- caret::train(x = train_x,
                      y = train_y,
                      method = "lda")

mean(predict(x_lda, newdata = test_x) == test_y)

x_qda <- caret::train(x = train_x,
                      y = train_y,
                      method = "qda")

mean(predict(x_qda, newdata = test_x) == test_y)

# Loess

x_loess <- caret::train(x = train_x,
                      y = train_y,
                      method = "gamLoess")

mean(predict(x_loess, newdata = test_x) == test_y)

# KNN
x_centered <- sweep(brca$x, 2, colMeans(brca$x))
x_scaled <- sweep(x_centered, 2, colSds(brca$x), FUN = "/")

set.seed(1, sample.kind = "Rounding")    # if using R 3.6 or later
test_index <- createDataPartition(brca$y, times = 1, p = 0.2, list = FALSE)
test_x <- x_scaled[test_index,]
test_y <- brca$y[test_index]
train_x <- x_scaled[-test_index,]
train_y <- brca$y[-test_index]

predict_kmeans <- function(x, k) {
    centers <- k$centers    # extract cluster centers
    # calculate distance to cluster centers
    distances <- sapply(1:nrow(x), function(i){
                        apply(centers, 1, function(y) dist(rbind(x[i,], y)))
                 })
  max.col(-t(distances))  # select cluster with min distance to center
}


# set.seed(3) if using R 3.5 or earlier
set.seed(3, sample.kind = "Rounding")    # if using R 3.6 or later
k <- kmeans(train_x, centers = 2)
summary(k)
kmeans_preds <- ifelse(predict_kmeans(test_x, k) == 1, "B", "M")
mean(kmeans_preds == test_y)

sensitivity(factor(kmeans_preds), test_y, positive = "M")


set.seed(7,sample.kind = "Rounding")
seq_knn <- data.frame(k = seq(3, 21, 2))
knn_fit <- train(train_x, train_y, method = "knn", tuneGrid = seq_knn)
mean(predict(knn_fit$finalModel, as.data.frame(test_x), type = "class") == test_y)

# Random Forest
set.seed(9, sample.kind = "Rounding")
tune_params <- data.frame(mtry = c(3, 5, 7, 9))
rf_fit <- train(train_x, train_y, method = "rf", tuneGrid = tune_params, importance = TRUE)
plot(rf_fit)
plot(varImp(rf_fit))

plot(rf_fit$finalModel)
plot(varImp(rf_fit$finalModel))


mean(predict(rf_fit$finalModel, as.data.frame(test_x), type = "class") == test_y)



# Ensembles
x_centered <- sweep(brca$x, 2, colMeans(brca$x))
x_scaled <- sweep(x_centered, 2, colSds(brca$x), FUN = "/")

set.seed(1, sample.kind = "Rounding")    # if using R 3.6 or later
test_index <- createDataPartition(brca$y, times = 1, p = 0.2, list = FALSE)
test_x <- x_scaled[test_index,]
test_y <- brca$y[test_index]
train_x <- x_scaled[-test_index,]
train_y <- brca$y[-test_index]

### Model 1 - K-means
model_kmeans <- kmeans(train_x, 2)
pred_kmeans <- recode(predict_kmeans(test_x, model_kmeans), "1" = "B", "2" = "M")
mean(recode(predict_kmeans(test_x, model_kmeans), "1" = "B", "2" = "M") == test_y)
pred_kmeans <- cbind(B = recode(pred_kmeans, "B" = 1, "M" = 0), 
                     M = recode(pred_kmeans, "B" = 0, "M" = 1))

### Model 2 - Logistic
model_log <- caret::train(x = train_x, y = train_y, method = "glm", family="binomial")
pred_log <- predict(model_log, as.data.frame(test_x), type="prob")
mean(predict(model_log, as.data.frame(test_x)) == test_y)

### Model 3 - LDA
model_lda <- caret::train(x = train_x, y = train_y, method = "lda")
pred_lda <- predict(model_lda, as.data.frame(test_x), type="prob")
mean(predict(model_lda, as.data.frame(test_x)) == test_y)

### Model 4 - QDA
model_qda <- caret::train(x = train_x, y = train_y, method = "qda")
pred_qda <- predict(model_qda, as.data.frame(test_x), type="prob")
mean(predict(model_qda, as.data.frame(test_x)) == test_y)

### Model 5 - Loess
model_loess <- caret::train(x = train_x, y = train_y, method = "gamLoess")
pred_loess <- predict(model_loess, as.data.frame(test_x), type="prob")
mean(predict(model_loess, as.data.frame(test_x)) == test_y)

### Model 6 - KNN
set.seed(7,sample.kind = "Rounding")
seq_knn <- data.frame(k = seq(3, 21, 2))
model_knn <- train(train_x, train_y, method = "knn", tuneGrid = seq_knn)
model_knn <- model_knn$finalModel
pred_knn <- predict(model_knn, as.data.frame(test_x), type="prob")
mean(predict(model_knn, as.data.frame(test_x), type="class") == test_y)

### Model 7 - Random Forest
set.seed(9, sample.kind = "Rounding")
tune_params <- data.frame(mtry = c(3, 5, 7, 9))
model_rf <- train(train_x, train_y, method = "rf", tuneGrid = tune_params, importance = TRUE)
model_rf <- model_rf$finalModel
mean(predict(model_rf, as.data.frame(test_x), type = "class") == test_y)
pred_rf <- predict(model_rf, as.data.frame(test_x), type="prob")


### Ensemble


pred_ensemble <- 
  (as.data.frame(pred_kmeans) 
   + pred_log 
   + pred_lda
   + pred_qda
   + pred_loess
   + pred_knn
   + pred_rf) / 7

mean(recode(apply(pred_ensemble, 1, which.max), "1" = "B", "2" = "M") == test_y)


```

```{r PCADemo}
set.seed(0)
x1 <- rnorm(100,0,8)
angle <- 0.523599
x2 <- x1 * tan(angle) + rnorm(100,0,3)
x1 <- x1 - mean(x1)
x2 <- x2 - mean(x2)

mydat <- data.frame(x1, x2)
mydat %>% ggplot(aes(x1,x2)) + geom_point() + xlim(c(-30,30)) + ylim(c(-30,30))

cov(mydat)

pca <- prcomp(mydat)

rot <- matrix(c(cos(-angle), -sin(-angle), sin(-angle), cos(-angle)), 2, 2)
rot

rotated_data <- as.matrix(mydat) %*% rot
rotated_data <- as.data.frame(rotated_data)

colnames(rotated_data) <- colnames(mydat)

lab1 <- rep("orgn", 100)
lab2 <- rep("rot", 100)

cbind(union(mydat, rotated_data), label = append(lab1, lab2)) %>%
  ggplot(aes(x1, x2, color = label)) + geom_point()

```

```{r Generative}

library(dslabs)
data("heights")

head(heights)

y <- heights$height
set.seed(1995)
test_index <- createDataPartition(y, times = 1, p = 0.5, list = FALSE)
train_set <- heights %>% slice(-test_index)
test_set <- heights %>% slice(test_index)

model_linreg <- train(y ~ height,
                      data = train_set %>% mutate(y = as.numeric(sex == "Female")),
                      method="lm")

model_logreg <- train(y ~ height,
                      data = train_set %>% mutate(y = as.factor(sex == "Female")),
                      method="glm",
                      family = "binomial")

cbind(train_set, fit = 1 - model_linreg$finalModel$fitted.values) %>%
  mutate(x = round(height)) %>%
  group_by(x) %>%
  summarise(prop = mean(sex == "Female"), pred = mean(fit)) %>%
  ggplot() + geom_point(aes(x, prop)) + geom_point(colour = "red", aes(x, pred))

plot(train_set$height, model_linreg$finalModel$fitted.values)


cbind(train_set, 
      lin = predict(model_linreg, newdata = train_set),
      log = model_logreg$finalModel$fitted.values) %>%
  mutate(x = round(height)) %>%
  group_by(x) %>%
  summarise(prop = mean(sex == "Female"), lin = mean(lin), log = mean(log)) %>%
  ggplot() + geom_point(aes(x,prop)) + geom_line(aes(x, lin), colour="blue") + geom_line(colour = "red", aes(x, log)) + xlim(c(60,80))


cbind(test_set, 
      lin = predict(model_linreg, newdata = test_set),
      log = 1 - predict(model_logreg, newdata = test_set, type="prob")[,1]) %>%
  mutate(x = round(height)) %>%
  group_by(x) %>%
  filter(n() >= 10) %>%
  summarise(prop = mean(sex == "Female"), lin = mean(lin), log = mean(log)) %>%
  ggplot() + geom_point(aes(x,prop)) + geom_line(aes(x, lin), colour="blue") + geom_line(colour = "red", aes(x, log))


```






